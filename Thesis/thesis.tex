\documentclass[twoside]{article}
\usepackage{iip11}

\begin{document}


\title{Сходимость алгоритма Аддитивной Регуляризации Тематических Моделей}
\author{Автор~И.\,О.}{Воронцов Константин Вячеславович$^1$}{vokov@forecsys.ru}
\author{Автор~И.\,О.}{Ирхин Илья Александрович$^{1}$\speaker}{ilirhinl@gmail.com}
\organization{%
    $^1$Московский Физико-Технический Институт, Россия, 141700, г. Долгопрудный, Институтский переулок, д. 9
 } 
\Russian
\maketitle

Вероятностное тематическое моделирование применяется для выявления  латентных тем в больших коллекциях текстов. В каждом конкретном приложении тематическая модель должна удовлетворять примерно десятку различных требований одновременно. Поэтому, чтобы упростить процесс моделирования, Константином Воронцовым в 2014 году был предложен не-байесовский многокритериальный подход, называемый Аддитивной Регуляризацией Тематических Моделей. Он основан на одновременной максимизации правдоподобия модели и множества дополнительных критериев-регуляризаторов. Преимущество АРТМ в том, что алгоритм выведен и реализован один раз в самом общем виде. На практике это позволяет строить сложные композитные модели с заданными свойствами.

Однако, до сих пор оставался открытым вопрос, при каких условиях этот алгоритм сходится. В данной работе такие условия были получены. Это было сделано за счёт интерпретации алгоритма АРТМ как GEM алгоритма. Неформально, алгоритм ARTM сходится, если регуляризатор воздействует на модель не слишком сильно, и есть определённая закономерность в обнулении и уменьшении основных параметров модели --- условных вероятностей тем в документах и в слов в темах. Был проведён эксперимент, который подтвердил выполнение предложенных условий сходимости на практике.

 Кроме того, были предложены две модификации М-шага, которые немного улучшают сходимость без увеличения вычислительной сложности. 

\begin{thebibliography}{1}
\bibitem{author16first-word-of-the-title}
    \emph{Автор\;И.\,О.}
    Название статьи~//
    Название журнала,
    Город: Издательство, 2016.~--- С.\,5--25. %\\
    \url{http://jmlda.org/papers/doc/2016/no1/Author2016Title.pdf}.
\end{thebibliography}


\title{Convergence of the algorithm of Additive Regularization of Topic Models }
\author{Author~N.}{Vorontsov Konstantin$^{1}$}{vokov@forecsys.ru}
\author{Author~N.}{Irkhin Ilya$^{1}$\speaker}{ilirhin@gmail.com}
\organization{%
    $^1$Moscow Institute of Physics and Technology, 9 Institutskii per., Dolgoprudny, Moscow Region, 141700, Russia
 } 
\English
\maketitle

Probabilistic topic modeling is applied to identify latent topics in large collections of texts. Depending on each specific application the topic model must meet about ten different requirements simultaneously. So, to simplify the process of modeling, Konstantin Vorontsov proposed a non-Bayesian multi-criteria approach, called Additive Regularization of Topic Models. It is based on the simultaneous maximization  of likelihood and a set of additional regularization criteria. The advantage of ARTM  is that its regularized Expectation Maximization algorithm is obtained and implemented once in the most general form. In practice, it gives an opportunity to build complex composite models with the desired properties.

There was an open question about convergence test for ARTM algorithm. These conditions were obtained in our work through interpreting the ARTM algorithm as GEM algorithm. 

Informally, ARTM algorithm converges if regularizer's effect on the model is not too big, and if there is a certain consistency in setting to zero and decreasing  of the main model parameters --- conditional probabilities of topics in documents and words in topics.  We conducted an experiment which confirmed that these conditions are satisfied in practice.

In addition, we proposed two modifications of the M-step, which slightly improve the convergence without increasing the computational complexity.
\begin{thebibliography}{1}
\bibitem{author16first-word-of-the-title}
    \emph{Author\;N.}
    Paper name~//
    Journal,
    City:~Publisher, 2016.~--- p.\,5--25.
    \url{http://jmlda.org/papers/doc/2016/no6/Author2016Title.pdf}.
\end{thebibliography}

\end{document}
