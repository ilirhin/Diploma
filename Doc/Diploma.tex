\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{MnSymbol}
\usepackage{wasysym}
\usepackage{mathtext}
\usepackage{mathenv}
\usepackage{listings}
\usepackage{color}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amssymb,amsfonts,amsmath,mathtext,cite,enumerate,float}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\usepackage[a4paper, left=25mm, right=20mm, top=20mm, bottom=20mm]{geometry}


\newtheorem{definition}{Определение}[section]
\newtheorem{remark}{Примечание}[subsection]
\newtheorem{suggest}[remark]{Соглашение}
\newtheorem{claim}[remark]{Утверждение}
\newtheorem{lemma}[remark]{Лемма}
\newtheorem{theorem}{Теорема}
\newtheorem{conseq}{Следствие}[theorem]
\newenvironment{Proof} 
	{\par\noindent{\bf Доказательство.}} 
	{\hfill$\blacksquare$}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true
  tabsize=3
}

\renewcommand{\baselinestretch}{1.4}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}

\DeclareMathOperator{\Supp}{Supp}
\DeclareMathOperator{\sparse}{sparse}

\begin{document}
\begin{titlepage}

\begin{center}

Министерство образования и науки Российской Федерации\\[1em]
Государственное образовательное учреждение\\
высшего профессионального образования \\
«МОСКОВСКИЙ ФИЗИКО-ТЕХНИЧЕСКИЙ ИНСТИТУТ \\
(ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ)»\\[1em]

\begin{minipage}{\textwidth}
\begin{flushleft}
\begin{tabular}{ l l }
Факультет & Инноваций и высоких технологий\\
Кафедра & Анализа данных
\end{tabular}
\end{flushleft}
\end{minipage}\\[1em]

\begin{minipage}{\textwidth}
\begin{flushright}
\textit{Тип работы:}\\
Выпускная квалификационная работа по направлению\\
010400 «Прикладные математика и информатика»
\end{flushright}
\end{minipage}\\[3em]


{Дипломная работа}\\
{на тему:}\\[1em]
\textbf{\large Сходимости численных методов вероятностного тематического моделирования}\\[6em]

\begin{minipage}{\textwidth}
\begin{flushright}
\textit{Научный руководитель:}\\
\underline{\hspace*{2.5cm}} К.\,В.~Воронцов
\end{flushright}
\end{minipage}\\[3em]

\begin{minipage}{\textwidth}
\begin{flushright}
\textit{Работу выполнил:}\\
Студент 093 группы\\
\underline{\hspace*{2.5cm}} И.\,А.~Ирхин
\end{flushright}
\end{minipage}\\[3em]

\vfill
{\normalsize Москва 2016}
\end{center}
\end{titlepage}


	\tableofcontents
	\newpage
	\renewcommand{\baselinestretch}{1.5}
	\section{Введение}
	Общий рассказаз про тематическое моделирование
	\subsection{Поднятые вопросы}
	В данной работе был поставлен вопрос \\
	\subsection{Полученные результаты} 
	Нами было  \\
	\section{Аддитивная регуляризация тематических моделей}

	\subsection{Классическая тематическая модель}
	TODO\\
	Здесь нужно сформулировать классическую задачу и расскать о её решении. Нужно упомянуть статьи \cite{plsadef1, plsadef2}
	

	\subsection{Добавление регуляризатора}
	TODO\\
	Здесь нужно сформулировать задачу при наличии регуляризатора и вывести общие формулы с отсылками на статьи \cite{artmdef1, artmdef2, artmdef3}\\
	Также указать преимущества ARTM (упомянув LDA \cite{ldadef1}\\
	В статье про ARTM на machinelearning очень хорошо написано

	\subsection{Приложения ARTM}
	TODO\\
	Рассказать об онлайн алгоритме (\cite{ldaonline1}, есть ли статьи по онлайн ARTM), о BigARTM (статьи), если есть статьи с применением сослаться на них

	\section{Сходимость метода ARTM}
	\subsection{ARTM как GEM алгоритм}
	Напомним,  перед нами стоит задача максимизации следующего функционала:
\[
L + \tau R = \sum_{w,d} n_{dw} \ln\sum_t \phi_{wt} \theta_{td} + \tau R(\phi, \theta) \to \max
\]
По аналогии с GEM алгоритмом введём дополнительный функционал:
\[
	Q(\phi, \theta, \phi', \theta') = \sum\limits_{d, w, t} n_{dw} p'_{tdw} \ln{\phi_{wt}\theta_{td}} + \tau R(\phi, \theta),
\]
где за $p'_{tdw}$ обозначено $\frac{\phi'_{wt} \theta'_{td}}{\sum\limits_t \phi'_{wt} \theta'_{td}}$, это обозначение будет активно использоваться в дальнейшем и для нештрихованных величин. \\
Наша цель -- увеличивать значение данного функционала по $\phi$ и $\theta$ в сравнении с $Q(\phi', \theta', \phi', \theta')$ на каждой итерации. Запишем задачу максимизации данного функционала:
\[
Q(\phi, \theta, \phi', \theta') \to \max_{\phi, \theta}.
\]
Если мы применим теорему Куна-Такера, мы получим, что стационарная точка $Q$ должна удовлетворять следующей системе:
\[
\left\{
	\begin{aligned}
		\phi_{wt} \propto \bigg( \sum\limits_d n_{dw} p'_{tdw} + \tau\phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}} \bigg)_{+},\\
		\theta_{td} \propto \bigg( \sum\limits_w n_{dw} p'_{tdw} + \tau\theta_{td} \frac{\partial{R}}{\partial{\theta_{td}}} \bigg)_{+}.
	\end{aligned}
\right.
\]
В итоге мы получили систему уравнений, похожых на итерации ARTM. Это означает, что каждую итерацию ARTM можно интерпретировать как попытку приблизить решение максимизационной задачи функционала $Q$, итерируя систему уравнений для стационарной точки $Q$. В зависимости от того какую точку мы будем брать начальной при итерировании системы уравнений, мы получим оба варианта итераций ARTM.\\
Если начальное приближение это $(\phi_{wt}, \theta_{td})$, то мы получим итерации
\[
\left\{
	\begin{aligned}
		\phi_{wt} \propto \bigg( n_{wt} + \tau\phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}} \big( \phi_{wt}, \theta_{td}\big) \bigg)_{+},\\
		\theta_{td} \propto \bigg( n_{td} + \tau\theta_{td} \frac{\partial{R}}{\partial{\theta_{td}}} \big( \phi_{wt}, \theta_{td}\big) \bigg)_{+}.
	\end{aligned}
\right.
\]
Если считать, что начальное приближение это $(\frac{n_{wt}}{n_t}, \frac{n_{td}}{n_d})$, то
\[
\left\{
	\begin{aligned}
		\phi_{wt} \propto \bigg( n_{wt} + \tau \frac{n_{wt}}{n_t} \frac{\partial{R}}{\partial{\phi_{wt}}} \big(\frac{n_{wt}}{n_t}, \frac{n_{td}}{n_d}\big) \bigg)_{+},\\
		\theta_{td} \propto \bigg(n_{td} + \tau \frac{n_{td}}{n_d} \frac{\partial{R}}{\partial{\theta_{td}}} \big(\frac{n_{wt}}{n_t}, \frac{n_{td}}{n_d}\big) \bigg)_{+}.
	\end{aligned}
\right.
\]
Таким образом, интерпретируя ARTM как итерации GEM алгоритма, мы можем использовать результаты о сходимостях GEM алгоритмов.
	\subsection{Теоремы о сходимости ARTM }
	\subsubsection{Итерации ARTM в обобщённом виде}	  
Итерации ARTM можно записать в следующем виде: \\
\textbf{E-step:}   
 
$
\begin{aligned}
& p_{tdw} \propto \varphi_{wt} \theta_{td}
\end{aligned}
$\medskip\\
\textbf{M-step:}

$
\begin{aligned}    
& n_{wt} = \sum\limits_{d} n_{dw} p_{tdw},~~n_{td} = \sum\limits_{w} n_{dw} p_{tdw}\\    
& r_{wt} =  \phi_{wt}\frac{\partial R}{\partial\phi_{wt}},~~ r_{td} =  \theta_{td}\frac{\partial R}{\partial\theta_{td}}\\
& \phi_{wt}  \propto \bigl(n_{wt} + r_{wt} \bigr)_{+},~~\theta_{td} \propto  \bigl(n_{td} + r_{td}\bigr)_{+}\\
\end{aligned}
$\medskip\\
Величины $r_{wt}$ и $r_{td}$ удобно называть регуляризационными добавками. Они являются какими-то функциями от $\Phi$ и $\Theta$. Фактичеки именно от их свойств зависит всё поведение алгоритма. Именно их мы и будем исследовать.


	\subsubsection{Ограниченные регуляризаторы}
	 В работе Wu \cite{wuem} были сформулированы достаточные условия для сходимости GEM алгоритма. Чтобы их сформулировать, нужно сначала ввести одно определение.
	\begin{definition}
	Будем говорить, что $A\colon X \to 2^X$ -- замкнутое point-to-set отображение, если из $x_k \to x$, $x \in X$, $y_k \to y$ и $y_k \in A(x_k)$ следует, что $y \in A(x)$.
	\end{definition}
	Итак, сформулируем теорему, немного изменив обозначения под ARTM:
	\begin{theorem} \label{theorem_wu} \ \\
	Пусть $\{\psi_p\}$ - GEM последовательность, сгенерированная правилосм $\psi_{p+1} \in M(\psi_p)$, где $M$ -- закмнутое point-to-set отображение. Пусть также значение $L + \tau R$ конечно и не уменьшается на итерациях, но приэтом ограниченно сверху, $|| \psi_p - \psi_{p+1}|| \to 0$, а множество стационарных точек $L + \tau R$ дискретно. Тогда $\psi_p$ сходится к некоторой стационарной точке $L + \tau R$.
	\end{theorem}
	Мы сведём нашу задачу к данной теореме, но сначала нам потребуется ввести новое определение.
	\begin{definition}
	Будем говорить, что регуляризатор $\tau R$ обладает свойством $\delta$-регулярности, если на итерациях ARTM $\forall t~\exists w \colon~n_{wt} + r_{wt} > \delta$ и аналогичное условие для $\theta$. Если регуляризатор  обладает свойством $\delta$-регулярности при каком-то $\delta > 0$, то будем говорить, что данный регуляризатор сильно регулярен.
	\end{definition}
	Это понятие обобщает понятие регулярности (легко видеть, что обычная регулярность это 0-регулярность по этому определению). Регулярность позволяла нам утверждать, что итерации ARTM корректно определены. Сильная же регулярность позволяет утверждать, что преобразования, которые мы совершаем на итерациях, не только определены, но и непрерывны. Что можно сказать о выполнении этого свойства на практике? Мы можем гарантировать его следующим образом: если значение выражения становится меньше $\delta$, то мы зануляем всю тему и выкидываем её, таким образом происходит селекция тем (например, мы могли изначально задать слишком большое число для количества тем).
	\begin{theorem} \label{theorem_neighbour_zero1} \ \\
	Пусть $R$ -- ограниченная сверху и дифференцируемая функция, причем, как регуляризатор, обладающая свойством регулярности. Также будем допустим,  что значение $Q(\phi, \theta, \phi', \theta')$ конечно и не уменьшается в сравнении $Q(\phi', \theta', \phi', \theta')$ на каждой итерации. Тогда при $d$ и $w$ т.ч. $n_{dw} > 0$ выполнено
\[
KL(p_{tdw}^{(n)}||p_{tdw}^{(n + 1)}) \to 0 \text{ при } n \to \infty.
\]
	\end{theorem}
	\begin{Proof}\ \\
Заметим, что $Q$ можно переписать следующим образом:
\[
Q(\phi, \theta, \phi', \theta') = L(\phi, \theta) + \tau R(\phi, \theta) + \sum\limits_{d, w, t} n_{dw} p'_{tdw} \ln{p_{tdw}}
\]
Пусть на итерации мы перешли в точку $\phi'', \theta''$. $Q$ не уменьшается на итерациях, значит
\[
	Q(\phi'', \theta'', \phi', \theta') \geq Q(\phi', \theta', \phi', \theta')
\]
Подставим вместо $Q$ его выражение:
\[
	L(\phi'', \theta'') + \tau R(\phi'', \theta'') + \sum\limits_{d, w, t} n_{dw} p'_{tdw} \ln{p''_{tdw}}  \geq L(\phi', \theta') + \tau R(\phi', \theta') + \sum\limits_{d, w, t} n_{dw} p'_{tdw} \ln{p'_{tdw}}
\]
\[
	\Delta(L + \tau R) \geq  \sum\limits_{d, w, t} n_{dw} p'_{tdw} \ln{\frac{p'_{tdw}}{p''_{tdw}}} = \sum\limits_{d, w} n_{dw} KL(p'_{dw} || p''_{dw}) \geq 0
\]
Таким образом $L + \tau R$  тоже не уменьшается. Но это ограниченная сверху функция, значит $(L + \tau R)^{(n)}$ сходится при $n \to \infty$. Более того при $n_{dw} > 0$:
\[
	KL(p_{tdw}^{(n)}||p_{tdw}^{(n + 1)}) \leq \Delta (L + \tau R)^{(n)} \to 0.
\]
\end{Proof}\ \\
\begin{conseq} \ \\
Если в дополнение к условиям Теоремы \ref{theorem_neighbour_zero1} $\tau R$ сильно регулярен, а $r_{wt}$ и $r_{td}$ непрерывны, то:
\[
|\phi_{wt}^{(n)} - \phi_{wt}^{(n+1)}| \to 0 \text{ и } |\theta_{td}^{(n)} - \theta_{td}^{(n+1)}| \to 0
\]
\end{conseq}
\begin{Proof}\ \\
По неравеству Пинскера \cite{pinsker} $||P - Q||_1 \leq 2\sqrt{KL(P||Q)}$. Поэтому сходимость по $KL$ влечёт за собой сходимость по $l_1$ норме. Осталось заметить, что в потребованных условиях  $\phi_{wt}$ и $\theta_{td}$ являются непрерывными функциями от $p_{tdw}$. А значит, сходимость вторых влечёт за собой сходимость первых.
\end{Proof}\ \\\
\begin{conseq} \ \\
В условия Следствия 1 все предельные точки $\phi$ и $\theta$ являются стационарными точками $L + \tau R$.
\end{conseq}
\begin{Proof}\ \\
Опишем коротко идею доказательства,  более подробно и формально оно описано в \cite{wuem}. Пусть  $\phi^0, \theta^0$ -- предельная точка. Мы знаем, что выполнено:
\[
Q(\phi, \theta, \phi^0, \theta^0) =  L(\phi, \theta) + \tau R(\phi, \theta) + \sum\limits_{d, w, t} n_{dw} p^0_{tdw} \ln{p_{tdw}}.
\]
Поскольку $\phi^0, \theta^0$  -- предельная точка, то значение $Q$ уже нельзя увеличить, а значит производная по $\phi$ и по $\theta$ левой части равна нулю. При $\phi = \phi^0$ и $\theta = \theta^0$ KL достигает минимума, а значит и его производные равны нулю. Таким образом получается, что и производные $L + \tau R$ равны нулю, что и требовалось доказать.
\end{Proof}\ \\
\begin{conseq} \ \\
Если в дополнение к условиям Следствия 1, множество стационарных точек $L + \tau R$ дискретно, то $\phi_{wt}^{(n)}$ и $\theta_{td}^{(n)}$ сходятся к стационарной точке $L + \tau R$.
\end{conseq}
\begin{Proof}\ \\
Положим $M(\phi, \theta) = \{artm(\phi, \theta)\}$, гле под $artm(\phi, \theta)$ понимается применение формул ARTM. В условиях Следствия 1 $artm$ -- непрерывное преобразование. Поэтому $M$ -- замкнутое point-to-set отображение. Остаётся заметить, что остальные условия Теоремы \ref{theorem_wu} тоже выполнены.
\end{Proof}\ \\
\subsubsection{Неограниченные регуляризаторы}
В предыдущем разделе нам была важна ограниченность $R$. Однако в ARTM частно используется регуляризатор разреживания $- \alpha \ln \phi_{wt}$, который не является ограниченным. Однако на практике данный регуляризатор прекрасно работает. В данном разделе мы постараемся понять почему. Основная идея состоит в том, что на практике у нас есть машинная точность $\varepsilon$, и все значения меньшие $\varepsilon$ считаются равными нулю. Это позволяет нам ограничить область значений снизу, и тем самым ограничить регуляризатор сверху. Также есть проблема с занулениями значений на итерациях, которую в предыдущем параграфе мы обошли за счёт сильного ограничения на $Q$. Тем не менее, при определённых  ограничениях на регуляризатор эти зануления будут структурированными, что позволит нам провести анализ. Теперь более подробно и более формально.
\begin{definition}
Будем говорить, что регуляризатор $\tau R$ сохраняет 0, если на итерациях $n_{wt} = 0 \implies \phi_{wt} = 0$ и $n_{td} = 0 \implies \theta_{td} = 0$
\end{definition}
Легко понять, что это определение формализует следующие свойство итераций: если на какой-то итерации значение $\phi_{wt}$ стало равным нулю, то оно будет оставаться нулевым всегда, и аналогично для $\theta_{td}$. Легко видеть, что это свойство легко проверяется аналитически. Остаётся отметить, что на практике все регуляризаторы обладают подобным свойством.
\begin{definition}
Будем говорить, что регуляризатор $\tau R$ $\varepsilon$-разреживающий, если на итерациях $\phi_{wt}, \theta_{td} \notin (0, \varepsilon)$.
\end{definition}
Данное свойство позволит нам формально учесть машинную точность (с этой точки зрения все регуляризаторы будут $\varepsilon$-разреживающими). Однако с точки зрения практики есть одна интересная особенность. Мы используем регуляризатор разреживания, чтобы каждой теме принадлежало лишь небольшое число слов. Фактически мы зануляем $n_{wt}$ , если его значение меньше $\alpha$, таким образом, после нормировки $\phi_{wt} \geq \frac{n_{wt} - \alpha}{n_t}$,  на реальных коллекциях очень часто происходит следующее: характерные слова темы $t$ имеют существенное значение $n_{wt}$ (например больше 1), а не характерные постепенно зануляются. В итоге мы получаем, что, начиная с некоторой итерации, $\phi_{wt} \notin (0, \frac{1-\alpha}{n_t})$ . Подробнее об этом вопросе мы поговорим в экспериментальной части.\\
Есть альтернативный способ добиться данного ограничения, достаточно заменить исходный регуляризатор на $-\alpha \ln \min(\phi_{wt}, \alpha)$. В этом случае мы получим, что на М-шаге мы зануляем выражения меньше $\alpha$ и не изменяем остальные значения. В этом случае $\phi_{wt}\notin (0, \frac{\alpha}{n_t})$. Мы опробуем данный способ в наших экспериментах.
\begin{definition}
Будем говорить, что регуляризатор $\tau R$ справедливый, если на итерациях $n_{dw} > 0 \implies \exists t\colon p_{tdw} > 0$.
\end{definition}
Это свойство -- чистая формальность. Поскольку мы будем производить разреживания, то мы не должны случайно занулить элемент матрицы $\Phi \Theta$ для которого $n_{dw} > 0$. Это привело бы к падению $L$ до -$\infty$.  Данное свойство в точности требует, чтобы такого не происходило. На практике оно обычно будет выполнено за счёт фоновых тем\cite{artmdef2}, поскольку они как правило дают небольшие вероятности для всех тем.\\
Итак, мы ввели три новых свойства регуляризатора, теперь мы можем доказать следующую теорему:

\begin{theorem} \label{theorem_neighbour_zero2} \ \\
	Пусть $R$ -- дифференцируемая функция при $\phi_{wt}, \theta_{td} \in (0, 1]$, причем, как регуляризатор, сохраняющая 0, справедливая, $\varepsilon$-разреживающая и обладающая свойством регулярности. Также будем допустим,  что значение $Q(\phi, \theta, \phi', \theta')$ конечно и не уменьшается в сравнении $Q(\phi', \theta', \phi', \theta')$, начиная с некоторой итерации. Тогда выполнено
\[
KL(p_{tdw}^{(n)}||p_{tdw}^{(n + 1)}) \to 0 \text{ при } n \to \infty.
\]
\end{theorem}
\begin{Proof}\ \\
Поскольку регуляризатор сохраняет 0, то с некоторой итерации множество позиций с нулевыми значениями в матрице $\Phi$ и $\Theta$ стабилизируется и не будет больше изменяться. Это очевидно следует из того факта, что  множество всех позиций конечно. В силу того, что регуляризатор $\varepsilon$-разреживающий значения в этих позициях будут $\geq \varepsilon$. Но $R$ -- дифференцируемая функция при $\phi_{wt}, \theta_{td} \in [\varepsilon, 1]$, а значит непрерывная и ограниченная. Далее мы можем повторить рассуждения Теоремы \ref{theorem_neighbour_zero1}, ограничивших значениями $\phi_{wt}$ и $\theta_{td}$ только в этих позициях. 
\end{Proof}\ \\
Также как и в случае Теоремы \ref{theorem_neighbour_zero1} данная теорема будет иметь аналогичные три следствия. Мы не будем приводить их ешё раз, так как они будут совпадать почти в каждом слове. Приведём только итоговую теорему, объединяющую все утверждения.
\begin{theorem} \label{theorem_convergence1} \ \\
	Пусть $R$ -- дифференцируемая функция при $\phi_{wt}, \theta_{td} \in (0, 1]$, причем, как регуляризатор, сохраняющая 0, справедливая, $\varepsilon$-разреживающая и обладающая свойством сильной регулярности, а  $r_{wt}$ и $r_{td}$ непрерывны. Также будем допустим,  что значение $Q(\phi, \theta, \phi', \theta')$ конечно и не уменьшается в сравнении $Q(\phi', \theta', \phi', \theta')$, начиная с некоторой итерации. Тогда если множество стационарных точек $L + \tau R$ дискретно при любой фиксации множества ненулевых позиций, то $\phi_{wt}^{(n)}$ и $\theta_{td}^{(n)}$ сходятся к стационарной точке $L + \tau R$ при ограничении на какое-то множество нулевых позиций.
\end{theorem}
Давайте проанализируем регуляризатор разреживания с точки зрения данной теоремыd в случае стандартных формул М-шага ($r_{wt} = \phi_{wt}\frac{\partial{R}}{\partial{\phi_{wt}}}$) . Свойство $\varepsilon$-разреживания мы уже обсудили ранее. Свойство справедивости обычно выполняется за счёт фоновых тем \cite{artmdef2} . Сохранение нуля данным регуляризатором и непрерывность $r_{wt}$ очевидны. Единственный важный момент -- это конечность $Q$ на итерациях. Если мы зануляем какое-то значение, то значение регуляризатора уходит в бесконечность. Чтобы избежать этого эффекта, надо считать $- [\phi_{wt} > 0] \ln\phi_{wt}$.\\
Таким образом, мы теперь можем ответить на вопрос, что происходит на итерациях ARTM (в предположении увеличения $Q$). По сути итерации можно разбить на два этапа: селекция ненулевых позиций и оптимизация. На первом этапе при помощи регуляризатора выбирается множество ненулевых позиций итогового решения. Понятно, что параллельно ведётся и оптимизация $L + \tau R$, но из наличия положительной срезки этот этап очень сложно анализировать. Его стоит воспринимать как подготовка начального приближения. На втором этапе оптимизация выходит на первый план. В силу того, что множество нулевых позиций не изменяется, положительную срезку в формулах можно убрать. Это облегчает анализ, более подробно об измении функционалов на итерациях мы поговорим в соответсвующей главе.

	\subsection{Cвойства траектории итерационного процесса ARTM}
Важным условием в теоремах сходимости является дискретность множества стационарных точек. В силу неединственности стохастического разложения матрицы (ссылка) это условие может не выполняться. Это подводит нас к поиску альтернативных достаточных условий сходимости. Сходимость итерационного процесса неразрывно связано со свойстами его траектории. Нам удалось связать свойства траектории процесса с изменениями $L + \tau R$.
\begin{theorem} \label{theorem_series}\ \\
	Пусть выполнены условия теоремы \ref{theorem_neighbour_zero1}. Тогда сходимость ряда
	\[
		\sum\limits_{n=1}^{\infty} (\Delta L^{(n)} + \tau \Delta R^{(n)})^{\alpha}
	\]
	влечёт за собой сходимость ряда
	\[
		\sum\limits_{n=1}^{\infty} (\Delta p_{tdw}^{(n)})^{2 \alpha}
	\]
\end{theorem}
\begin{Proof}\ \\
Нами было доказано, что $KL(p_{tdw}^{(n)}||p_{tdw}^{(n + 1)}) \leq \Delta (L + \tau R)^{(n)}$. По неравенству Пинскера $|| p_{dw}^{(n)} - p_{dw}^{(n+1)}||_1 \leq C \cdot \sqrt{KL(p_{tdw}^{(n)}||p_{tdw}^{(n+1)})} \leq C \sqrt{\Delta (L + \tau R)^{(n)}}$. А значит, $ (\Delta p_{tdw}^{(n)})^{2} \leq C^2 \Delta (L + \tau R)^{(n)} $, откуда очевидно следует требуемое утверждение.
\end{Proof}\ \\
\begin{conseq}
В условиях теоремы  \ref{theorem_neighbour_zero1} ряд  $\sum\limits_{n=1}^{\infty} (\Delta p_{tdw}^{(n)})^{2 \alpha}$ сходится при $\alpha \geq 1$.
\end{conseq}
\begin{Proof}\ \\
Монотонность по $\alpha$ свойства сходимости очевидна. При $\alpha=1$ мы имеем
\[
\sum\limits_{n=1}^{m} (\Delta L^{(n)} + \tau \Delta R^{(n)}) = ( L^{(m)} + \tau R^{(m)}) - ( L^{(0)} + \tau R^{(0)})
\]
А сходимость данной последовательности мы уже доказывали.
\end{Proof}\ \\
\begin{conseq}
В условиях теоремы  \ref{theorem_convergence1} условие дискретности множества стационарных точек можно заменить условием сходимости ряда
\[
\sum\limits_{n=1}^{\infty} \sqrt{\Delta L^{(n)} + \tau \Delta R^{(n)}}.
\]
\end{conseq}
К сожалению, это абсолютно неконструктивное условие. Однако, стоит взять во внимание, что при вычислениях, начиная с некоторого момента, изменения функционалов меньше машинной точности, и к этому моменту на практике частичная сумма ряда не уходит в бесконечность. Поэтому вычислительно на реальных коллекциях этот ряд сходится. Также стоит отметить, что с такой точки зрения полученная точка  сходимости будет вычислительно стационарной.
	\subsection{Изменение регуляризационного правдоподобия на итерациях ARTM}
	\subsubsection{Общий анализ}
В данной главе под $Q^{\prime}$ будем понимать $\sum\limits_{d, w, t} n_{dw} p'_{tdw} \ln{\phi_{wt}\theta_{td}}$. То есть $Q = Q^{\prime} + \tau R$.\\
Напомним, у нас есть два набора формул для регуляризационных добавок на М-шаге:
\[
\left\{
	\begin{aligned}
		r_{wt}= \tau\phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}},\\
		r_{td} = \tau\theta_{td} \frac{\partial{R}}{\partial{\theta_{td}}}.
	\end{aligned}
\right.
\text{~~и~~}
\left\{
	\begin{aligned}
		r_{wt} = \tau \frac{n_{wt}}{n_t} \frac{\partial{R}}{\partial{\phi_{wt}}} \biggl(\frac{n_{wt}}{n_t}, \frac{n_{td}}{n_d}\biggr),\\
		r_{td}= \tau \frac{n_{td}}{n_d} \frac{\partial{R}}{\partial{\theta_{td}}} \biggl(\frac{n_{wt}}{n_t}, \frac{n_{td}}{n_d}\biggr).
	\end{aligned}
\right.
\]
Само обновление параметров происходит по формуле 
\[
\left\{
\begin{aligned}
 \phi_{wt}  \propto \bigl(n_{wt} + r_{wt} \bigr)_{+},\\
\theta_{td} \propto  \bigl(n_{td} + r_{td}\bigr)_{+}
\end{aligned}
\right.
\]
Проводить анализ суммарного измеения функционала $Q$ по такой формуле слишком обременительно. Поэтому мы разложим это преобразование на два этапа. Первый этап -- максимизация $Q^{\prime}$:
\[
\left\{
	\begin{aligned}
		\phi_{wt} \propto n_{wt},\\
		\theta_{td} \propto n_{td} .
	\end{aligned}
\right.
\]
и второй этап (назовём его регуляризационным преобразованием) -- максимизация $R$:
\[
\left\{
\begin{aligned}
 \phi_{wt}  \propto \bigl(n_{wt} + r_{wt} \bigr)_{+},\\
\theta_{td} \propto  \bigl(n_{td} + r_{td}\bigr)_{+}
\end{aligned}
\right.
\]
Будем оценивать изменения функционалов отдельно по данным этапам. Для начала проанализируем эти этапы. Мы переходим в точку $(\frac{n_{wt}}{n_t}, \frac{n_{td}}{n_d})$ на первом шаге, а затем стараемся максимизировать $R$. Как мы говорили, есть два варианта для формул регуляризационных добавок. Напомним их на примере $r_{wt}$. В первом случае $r_{wt} = \tau\phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}} \big( \phi_{wt}, \theta_{td}\big)$, а во втором $\phi_{wt} = \frac{n_{wt}}{n_t} \frac{\partial{R}}{\partial{\phi_{wt}}} \big(\frac{n_{wt}}{n_t}, \frac{n_{td}}{n_d}\big)$. Первый способ предлагает определить добавку в начальной точке и потом её использовать, второй способ определяет добавку уже в новой точке. Понятно, что второй способ формально должен лучше максимизировать $R$, так как он выбирает добавку по более актуальной информации. Для первого варианта нам не удалось провести анализ, так как неясно как связаны градиент в точке $(\phi_{wt}, \theta_{td})$ и $(\frac{n_{wt}}{n_t}, \frac{n_{td}}{n_d})$. Для второго варианта анализ оказался весьма успешнее. В частности, для него верна следующая лемма:
\begin{lemma}           
 В ходе регуляризационного преобразования  без занулений, угол  между вектором изменений и градиентом $R$ острый, если градиент ненулевой.
\end{lemma}
\begin{Proof}\\
Рассмотрим функцию $R^{\prime}$ зависящую от $n_{wt}$ следующим образом: $R^{\prime}(n_{wt}, n_{td}) = R( \frac{n_{wt}}{\sum\limits_w n_{wt}},  \frac{n_{td}}{\sum\limits_t n_{td}})$. \\
Далее для простоты рассмотрим случай $R(\Phi, \Theta) = R(\Phi)$. В этом случае 
\[
\frac{\partial{\phi_{ut}}}{\partial{n_{wt}}} = \frac{\partial{ \frac{n_{ut}}{\sum\limits_v n_{vt}}}}{\partial{n_{wt}}} = \frac{ \frac{\partial{n_{ut}}}{\partial{n_{wt}}}}{\sum\limits_v n_{vt}} - \frac{n_{ut}}{(\sum\limits_v n_{vt})^2} = I\{u = w\} \frac{1}{n_t} - \frac{\phi_{ut}}{n_t} = \frac{1}{n_t}\bigg( 
 I\{u = w\} - \phi_{ut} \bigg)
\]
\[
\frac{\partial{R^{\prime}}}{\partial{n_{wt}}} = \sum_{u} \frac{\partial{R}}{\partial{\phi_{ut}}} \frac{\partial{\phi_{ut}}}{\partial{n_{wt}}} = \frac{1}{n_t} \bigg( \frac{\partial{R}}{\partial{\phi_{wt}}} - \sum_{u}  \frac{\partial{R}}{\partial{\phi_{ut}}} \phi_{wt} \bigg) = \frac{1}{n_t} \bigg( \frac{\partial{R}}{\partial{\phi_{wt}}} - \sum_{u}  \frac{\partial{R}}{\partial{\phi_{ut}}} \phi_{ut} \bigg) = \frac{1}{n_t} \sum_{u} \bigg(\frac{\partial{R}}{\partial{\phi_{wt}}}  -  \frac{\partial{R}}{\partial{\phi_{ut}}} \bigg)  \phi_{ut}
\]
С другой стороны $\Delta n_{wt} = \tau \phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}}$, поскольку мы отождествляем $\phi_{wt}$ и $\frac{n_{wt}}{\sum\limits_w n_{wt}}$. Отсюда
\[
\langle \Delta n, grad\ R^{\prime}(n_{wt}, n_{td})\rangle = \sum\limits_{w, t, u}  \frac{1}{n_{t}}  \bigg(  \frac{\partial{R}}{\partial{\phi_{wt}}}  -  \frac{\partial{R}}{\partial{\phi_{ut}}}  \bigg)  \tau \frac{\partial{R}}{\partial{\phi_{wt}}} \phi_{wt} \phi_{ut}
\]
Если переобозначить $u$ за $w$ и наоборот, то 
\[
\sum\limits_{w, t, u}  \frac{1}{n_{t}}  \bigg(  \frac{\partial{R}}{\partial{\phi_{wt}}}  -  \frac{\partial{R}}{\partial{\phi_{ut}}}  \bigg)  \tau \frac{\partial{R}}{\partial{\phi_{wt}}} \phi_{wt} \phi_{ut}  = \sum\limits_{w, t, u}  \frac{1}{n_{t}}  \bigg(  \frac{\partial{R}}{\partial{\phi_{ut}}}  -  \frac{\partial{R}}{\partial{\phi_{wt}}}  \bigg)  \tau \frac{\partial{R}}{\partial{\phi_{ut}}} \phi_{wt} \phi_{ut} = 
\]
\[
= \sum\limits_{w, t, u}  \frac{1}{n_{t}}  \bigg(  \frac{\partial{R}}{\partial{\phi_{wt}}}  -  \frac{\partial{R}}{\partial{\phi_{ut}}}  \bigg)  \tau \big(-\frac{\partial{R}}{\partial{\phi_{ut}}}\big) \phi_{wt} \phi_{ut} = 
\]
\[
= \frac12 \bigg(\sum\limits_{w, t, u}  \frac{1}{n_{t}}  \bigg(  \frac{\partial{R}}{\partial{\phi_{wt}}}  -  \frac{\partial{R}}{\partial{\phi_{ut}}}  \bigg)  \tau \frac{\partial{R}}{\partial{\phi_{wt}}} \phi_{wt} \phi_{ut} +  \sum\limits_{w, t, u}  \frac{1}{n_{t}}  \bigg(  \frac{\partial{R}}{\partial{\phi_{wt}}}  -  \frac{\partial{R}}{\partial{\phi_{ut}}}  \bigg)  \tau \big(-\frac{\partial{R}}{\partial{\phi_{ut}}}\big) \phi_{wt} \phi_{ut} \bigg)= 
\]
\[
= \frac12 \tau \sum\limits_{t, w, u}  \frac{1}{n_{t}} \bigg(  \frac{\partial{R}}{\partial{\phi_{wt}}}  -  \frac{\partial{R}}{\partial{\phi_{ut}}}  \bigg)^2 \phi_{wt} \phi_{ut} = \tau \sum\limits_{t, w < u}  \frac{1}{n_{t}} \bigg(  \frac{\partial{R}}{\partial{\phi_{wt}}}  -  \frac{\partial{R}}{\partial{\phi_{ut}}}  \bigg)^2 \phi_{wt} \phi_{ut} \geq 0
\]
Пусть достигается равенство, тогда $\frac{\partial{R}}{\partial{\phi_{wt}}}  =  \frac{\partial{R}}{\partial{\phi_{ut}}}$ для всех $u$ и $w$. Тогда
\[
\frac{\partial{R^{\prime}}}{\partial{n_{wt}}} = \frac{1}{n_t} \bigg( \frac{\partial{R}}{\partial{\phi_{wt}}} - \sum_{u}  \frac{\partial{R}}{\partial{\phi_{ut}}} \phi_{ut} \bigg) = \frac{1}{n_t} \bigg( \frac{\partial{R}}{\partial{\phi_{wt}}} - \sum_{u}  \frac{\partial{R}}{\partial{\phi_{wt}}} \phi_{ut} \bigg) =
\]
\[
=\frac{1}{n_t} \bigg( \frac{\partial{R}}{\partial{\phi_{wt}}} - \frac{\partial{R}}{\partial{\phi_{wt}}} \sum_{u} \phi_{ut} \bigg)  = \frac{1}{n_t} \bigg( \frac{\partial{R}}{\partial{\phi_{wt}}} - \frac{\partial{R}}{\partial{\phi_{wt}}} \bigg) = 0
\]
Значит градиент нулевой -- противоречие. Значит равенство строгое и угол острый.
\end{Proof}\ \\
\ \\
В прошлой главе мы доказывали, что при определённых условиях на регуляризатор занулений не будет, начиная с некоторой итерации. Таким образом, если коэффициент $\tau$ не слишком большой, то на регуляризационном преобразовании будет происходить увеличение $R$ в силу малого изменения $n_{wt}$.\\
\ \\
Теперь нужно объединить результаты двух итераций. В ходе первого шага мы переходим в точку максимума $Q^{\prime}$, значит градиент $Q^{\prime}$ в данной точке нулевой. Это означает, что в данной точке градиент $Q^{\prime} + \tau R$ сонаправлен с градиентом $R$, что означает, что на шаге регуляризационного преобразования происходит неуменьшение $Q^{\prime} + \tau R$. Осталось понять, как изменяется данный функционал на первом шаге. Начиная с некоторого момента изменения $Q^{\prime}$ становятся незначительны, а это означает, что поскольку мы максимизируем $Q^{\prime} + \tau R$ в локальной окрестности, в которой находится и исходная точка, а значит она была потенциальным кандидатом при выборе улучшения, но если мы выбрали другое направление, то мы увеличиваем значение $Q^{\prime} + \tau R$ по сравнению с исходным.\\
\subsubsection{Использование градиента регуляризатора}
У вышеописанного рассуждения есть два допущения. Первое, мы считаем, что изменения $\phi$ и $\theta$ невелики, обычно так и есть после нескольких первых итераций, когда основные частоты посчитаются и мы  перестанем делать большие скачки в пространстве матриц. Второе, мы считаем, что мы локально максимизируем $Q^{\prime} + \tau R$, однако мы доказали, что происходит увеличение, а не максимизация. Тем не менее, существует несколько способов обойти это условие. Во-первых, на практике угол очень острый, что позволяет производить требуемое увеличение. Во-вторых, мы можем выбирать направление между предлагаемым направлением и направлением на старую точку. В третьих, можно использовать градиент в качестве $r_{wt}$. Тогда направление изменения при регуляризационном преобразовании будет совпадать с направлением градиента, а значит будет локальная максимизация. То есть предлагается использовать следующую формулу для регуляризационных добавок на М-шаге:
\[
\left\{
	\begin{aligned}
		r_{wt} = \tau A_t \bigg[{\frac{\partial{R}}{\partial{\phi_{wt}}} - \sum\limits_u \phi_{ut} \frac{\partial{R}}{\partial{\phi_{ut}}} }\bigg] \bigg(\frac{n_{wt}}{n_t}, \frac{n_{td}}{n_d}\bigg),\\
		r_{td} = \tau B_d \bigg[ {\frac{\partial{R}}{\partial{\theta_{td}}} - \sum\limits_s \theta_{sd} \frac{\partial{R}}{\partial{\theta_{sd}}} }\bigg] \bigg(\frac{n_{wt}}{n_t}, \frac{n_{td}}{n_d}\bigg) ,
	\end{aligned}
\right.
\]
где $A_t$ и $B_d$ это какие-то константы, мы использовали $A_t = \frac{1}{n_t}$ и $B_d = \frac{1}{n_d}$.\\
Такие добавки можно эффективно вычислить, поскольку второк слагаемое общее для всех слов(тем). Поэтому его можно считать кумулятивно при первом пробега, на котором считается первое слагаемое. А затем на втором пробеге вычесть его из всез добавок. Таким образом асимптотика работы не увеличится. 

Градиент регуляризатора можно использовать ещё одним способом. Мы можем сделать подмену регуляризатора. Пусть $S$ т.ч. $\phi_{wt}\frac{\partial{R}}{\partial{\phi_{wt}}} = C_t \bigg( \frac{\partial{S}}{\partial{\phi_{wt}}} - \sum_{u}  \frac{\partial{S}}{\partial{\phi_{ut}}} \phi_{ut} \bigg)$, где $C_t$ -- какая-то константа. Тогда мы можем применить все наши рассуждения к данному регуляризатору, но для анализа использовать функционал $Q^{\prime} + \tau S$. Тогда направление изменения при регуляризационном преобразовании будет совпадать с направлением градиента, а значит будет локальная максимизация. К сожалению, решение данной системы уравнений в частных производных затруднено тем фактом, что матрица коэффициентов вырождено, что означает, что решение существует не всегда (на текущий момент есть гипотеза, что необходимым и достаточным условием является $\sum \phi_{wt}^2 \frac{\partial{R}}{\partial{\phi_{wt}}} = 0$). Анализ данного уравнения является перпективой дальнейшей работы.
           \subsubsection{Классификация регуляризаторов}
Точки зрения изменения функционала $Q$ стоит выделить несколько типов регуляризаторов.\\
	 \textbf{Аналитические регуляризаторы}. В эту группу попадают регуляризаторы, для которых мы можем явно найти решение максимизационной задачи $Q$. В этом случае нам не требуется анализировать углы между градиентами, мы получим увеличение функционала просто по построению. Таковыми регуляризаторами являются, например, регуляризаторы сглаживания и разреживания.\\ 
	\textbf{Вогнутые регуляризаторы}. Функционал $Q^{\prime}$ -- вогнут, если $R$ тоже вогнутая функция, то $Q^{\prime} + \tau R$ тоже вогнутая функция, поэтому имеет единственный максимум. Мы доказали, что будет происходить увеличение $Q^{\prime} + \tau R$ при некоторых допущениях. Однако в случае случае вогнутого регулязиратора мы можем сказать, что на шаге регуляризационного преобразования мы приближаемся к глобальному максимуму, а не просто увеличиваем значение. Таковыми регуляризаторами являются регуляризаторы когерентности и лапласианы графов связей документов.\\
	\textbf{Неограниченные регуляризаторы}. В случае если регуляризатор неограничен мы получаем некорректую постановку оптимизационной задачи. Более подробно мы рассматривали эту проблему в предыдущем разделе.\\
	\textbf{Произвольные регуляризаторы}. Для произвольных регуляризаторов мы доказали увеличение $R$ при регуляризационном преобразовании, при дополнительных условиях оно преобразуется в увеличение $Q^{\prime} + \tau R$ на итерациях. Здесь наиболее интересно научиться делать подмену регуляризатора по системе уравнений, которую мы описали ранее.

 \subsubsection{Различия предложенных М-шагов}
Пусть $R = -\tau \sum\limits_{w, t} \phi_{wt}$. Формально он не должен влиять на оптимизацию, поскольку просто равен константе при ограничениях задачи. Однако, стандартные формулы дадут следующий М-шаг:
\[
\left\{
	\begin{aligned}
		\phi_{wt} \propto \bigl( n_{wt} - \tau \phi_{wt}\bigr)_{+},\\
		\theta_{td} \propto \bigl( n_{td} - \tau \theta_{td}\bigr)_{+}.
	\end{aligned}
\right.
\]
Этот процесс сойдётся, возможно (если не будет занулений) к тому же самому, что и PLSA, но траектория будет другой. Используя несмещённые оценки, можно получить.
\[
\left\{
	\begin{aligned}
		\phi_{wt} \propto  \sparse_{\tau}(n_{wt}, n_{t}),\\
		\theta_{td} \propto \sparse_{\tau}(n_{td}, n_{d}),
	\end{aligned}
\right.
\]
где $\sparse_{\tau}(x, y) = x$, если $\tau < y$ и $0$ иначе. Это уже практически PLSA, но с условием, на селекцию тем (тема должна содержать какое-то минимальнок число слов, иначе мы просто занулим все  значения).
Использование градиентной добавки даёт 
\[
r_{wt} \propto \frac{\partial{R}}{\partial{\phi_{wt}}} - \sum\limits_u \phi_{ut} \frac{\partial{R}}{\partial{\phi_{ut}}} = -\tau + \tau =0
\]
То есть в точности PLSA.\\

Этот пример показывает, что градиентная добавка менее склонна к занулению параметров. Это наводит на мысль, что вначале можно использовать обычные формулы М-шага, или несмещённые оценки для селекции тем. А затем использовать градиентную поправку для более точной настройки параметров.\\

Возможно стоит ещё примеров придумать.
           \subsection{Стремление коэффициентов к нулю}
Важным нашим интрументом для анализа регуляризационного преобразования был подсчёт градиента, не по $\phi_{wt}$, а по $n_{wt}$. Используя данный подход, мы можем доказать следующее утверждения для коэффициентов регуляризации, стремлящихся к нулю.\\
\begin{claim}
Существует такая константа $\gamma$, что если $\tau_n \leq \gamma \Delta Q^{\prime}_n$, а также $\frac{1}{n_t} \frac{\partial{R}}{\partial{\phi_{wt}}}(n_{wt}, n_{td})$ -- ограниченная функция (константой $C$). То по формулам ARTM с заменой несмещёнными оценками на итерациях $\Delta Q^{\prime}_n \geq 0$.
\end{claim}
\begin{Proof}
\ \\
Для простоты рассмотрим случай $R(\Phi, \Theta) = R(\Phi)$. \\
При регуляризационном сглаживании  $\Delta n_{wt} = \bigg( n_{wt} + \tau_n \phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}}\bigg)_{+} - n_{wt} = \alpha_{wt} \phi_{wt}$.\\
\[
\bigg( n_{wt} + \tau_n \phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}}\bigg)_{+} - n_{wt} \leq  n_{wt} +\bigg| \tau_n \phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}}\bigg| - n_{wt} \leq \bigg| \tau_n \phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}}\bigg|
\]
\[
\bigg( n_{wt} + \tau_n \phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}}\bigg)_{+} - n_{wt} \geq  n_{wt} - \bigg| \tau_n \phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}}\bigg| - n_{wt} \geq - \bigg| \tau_n \phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}}\bigg|
\]
\[
|\Delta n_{wt} | \leq \tau_n\bigg|  \phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}}\bigg| \leq \tau_n n_{wt} C \leq \tau_n n_{w} C
\]
Мы уже считали градиент $R$ в предыдущей главе, поэтому просто подставим:
\[
 \bigg|\langle\Delta n, grad R(n_{wt}, n_{td}) \rangle\bigg| = \bigg| \sum\limits_{w, t, u}  \frac{1}{n_{t}}  \bigg(  \frac{\partial{R}}{\partial{\phi_{wt}}}  -  \frac{\partial{R}}{\partial{\phi_{ut}}}  \bigg)  \Delta n_{wt}  \phi_{ut} \bigg| \leq 2C^2\sum_w n_w  \tau_n \leq 2 \gamma C^2n \Delta Q^{\prime}_n
\]
Если $ 2 \gamma C^2n < 1$, то изменение $Q^{\prime}_n$ при регуляризационном преобразовании меньше чем при максимизации $Q^{\prime}_n$, а значит суммарный эффект будет положительным.
\end{Proof}\ \\
\ \\
Приведём простой пример того, как можно управлять коэффициентами регуляризации. Давайте, следить за тем, чтобы $Q^{\prime}_n$ всегда увеличивалось, а в случае, если оно не увеличивается, будем уменьшать $\tau_n$ (например домножением на 0.95).

	\section{Практические исследования}
\subsection{Используемая коллекция данных}
Нам была нужна достаточно большая коллекция документов, с заранее известным  и небольшим числом тем. 20Newsgroup не подошла, так как там слишком мало документов, Википедия не подошла поскольку содержит слишком много тем. Поэтому нами была собрана собственная коллекция документов. Мы скачали статьи с спортивного сайта sports.ru по разным видам спорта, темой документа мы считали вид спорта. Получившаяся коллекция документов состоит из 7 видов спорта, примерно по 3000 статей в каждом. Нами была проведена лемматизация текста и удаление стоп слов. Итоговые параметры коллекции: $|W| = 18831,~|D| = 21001,~|T| = 7$. \textbf{Возможно, стоит к защите на ещё какой-нибудь коллекции сделать}
	\subsection{Сравниваемые алгоритмы}
Было проведено сравнение трёх алгоритмов: стандартного, несмещённой модификации М-шага и градиентной модификации М-шага. Приведём описание данных алгоритмов.

\begin{algorithm}
\caption{ARTM. Стандартный М-шаг}\label{malgo1}
\begin{algorithmic}[]
\Procedure{MStep}{$n_{wt}$, $n_{td}$, $\phi_{wt}$, $\theta_{td}$}
\State 1. Для всех пар $w$, $t$ вычислить $r_{wt} = \tau \phi_{wt} \frac{\partial{R}}{\partial{\phi_{wt}}}(\phi_{wt}, \theta_{td})$
\State 2. Для всех пар $t$, $d$ вычислить $r_{td} =\tau  \theta_{td} \frac{\partial{R}}{\partial{\theta_{td}}}(\phi_{wt}, \theta_{td})$
\State 3. Для всех пар $w$, $t$ обновить счётчики $n_{wt} = \max(n_{wt} + r_{wt}, 0)$
\State 4. Для всех пар $t$, $d$ обновить счётчики $n_{td} = \max(n_{td} + r_{td}, 0)$
\State 5. Вычислить нормировочные множители $n_t = \sum_w n_{wt}$ и $n_d = \sum_t n_{td}$
\State 6. Для всех пар $w$, $t$ вычислить $\phi_{wt} = \frac{n_{wt}}{n_t}$
\State 7. Для всех пар $t$, $d$ вычислить $\theta_{td} = \frac{n_{td}}{n_d}$
\EndProcedure
\end{algorithmic}
\end{algorithm}
\begin{algorithm}
\caption{ARTM. Несмещённый М-шаг}\label{malgo2}
\begin{algorithmic}[]
\Procedure{MStep}{$n_{wt}$, $n_{td}$, $\phi_{wt}$, $\theta_{td}$}
\State 1. Вычислить нормировочные множители $n^{\prime}_t = \sum_w n_{wt}$ и $n^{\prime}_d = \sum_t n_{td}$
\State 2. Для всех пар $w$, $t$ вычислить $r_{wt}= \tau \frac{n_{wt}}{n^{\prime}_t}\frac{\partial{R}}{\partial{\phi_{wt}}}(\frac{n_{wt}}{n^{\prime}_t}, \frac{n_{td}}{n^{\prime}_d})$
\State 3. Для всех пар $t$, $d$ вычислить $r_{td}= \tau \frac{n_{td}}{n^{\prime}_d}\frac{\partial{R}}{\partial{\theta_{td}}}(\frac{n_{wt}}{n^{\prime}_t}, \frac{n_{td}}{n^{\prime}_d})$
\State 4. Для всех пар $w$, $t$ обновить счётчики $n_{wt} = \max(n_{wt} + r_{wt}, 0)$
\State 5. Для всех пар $t$, $d$ обновить счётчики $n_{td} = \max(n_{td} + r_{td}, 0)$
\State 6. Вычислить нормировочные множители $n_t = \sum_w n_{wt}$ и $n_d = \sum_t n_{td}$
\State 7. Для всех пар $w$, $t$ вычислить $\phi_{wt} = \frac{n_{wt}}{n_t}$
\State 8. Для всех пар $t$, $d$ вычислить $\theta_{td} = \frac{n_{td}}{n_d}$
\EndProcedure
\end{algorithmic}
\end{algorithm}
\begin{algorithm}
\caption{ARTM. Градиентный М-шаг}\label{malgo3}
\begin{algorithmic}[]
\Procedure{MStep}{$n_{wt}$, $n_{td}$, $\phi_{wt}$, $\theta_{td}$}
\State 1. Вычислить нормировочные множители $n^{\prime}_t = \sum_w n_{wt}$ и $n^{\prime}_d = \sum_t n_{td}$
\State 2. Для всех пар $w$, $t$ вычислить $r_{wt}= \tau \frac{1}{n^{\prime}_t} \frac{\partial{R}}{\partial{\phi_{wt}}}(\frac{n_{wt}}{n^{\prime}_t}, \frac{n_{td}}{n^{\prime}_d})$
\State 3. Для всех пар $t$, $d$ вычислить $r_{td}= \tau \frac{1}{n^{\prime}_d} \frac{\partial{R}}{\partial{\theta_{td}}}(\frac{n_{wt}}{n^{\prime}_t}, \frac{n_{td}}{n^{\prime}_d})$
\State 6. Вычислить $r_t = \sum_w \frac{n_{wt}}{n^{\prime}_t} r_{wt}$ и $r_d = \sum_t \frac{n_{td}}{n^{\prime}_d} r_{td}$
\State 4. Для всех пар $w$, $t$ обновить счётчики $n_{wt} = \max(n_{wt} + r_{wt} - r_t, 0)$
\State 5. Для всех пар $t$, $d$ обновить счётчики $n_{td} = \max(n_{td} + r_{td} - r_t, 0)$
\State 6. Вычислить нормировочные множители $n_t = \sum_w n_{wt}$ и $n_d = \sum_t n_{td}$
\State 7. Для всех пар $w$, $t$ вычислить $\phi_{wt} = \frac{n_{wt}}{n_t}$
\State 8. Для всех пар $t$, $d$ вычислить $\theta_{td} = \frac{n_{td}}{n_d}$
\EndProcedure
\end{algorithmic}
\end{algorithm}\ \\
\newpage

	
\subsection{Исследуемые величины}
В качестве объекта экспериментов был выбран регуляризатор декоррелирования: $R = \sum_w \sum_{s \neq t} \phi_{wt} \phi_{ws}$. Мы использовали три разных значения $\tau$: $-10^5$, $-10^6$, $-10^8$. Значения отрицательные поскольку мы хотим уменьшить корреляции тем. Также проверерялись разные количества тем: 3, 10, 30, чтобы проверить воредение алгоритма в случаях недооценки, хорошей оценки и переоценки  количества тем.  Нас интересовали следующие величины:
\begin{enumerate}
\item Минимальное ненулевое значение в матрицах $\Phi$ и $\Theta$. Это проверка гипотезы  отделимости от нуля.
\item Значение $L$, $R$ и $L + \tau R$ на итерациях. Это проверка качества оптимизации.
\item Изменение $R$ при выполнении М-шага. Тут возникла небольшая проблема. Дело в том, что значения $r_{wt}$ по модулю  при градиентной модификации на порядок меньше значений при стандартном М-шаге или несмещённой модификации. Поэтому чтобы более точно сравнить качество оптимизации нормировать изменение $R$ на норму ($l_1$ и $l_2$) вектора $r_{wt}$.
\item Значения знаменателя (это $n_t$ и $n_d$) на М-шаге.
\end{enumerate}
Алгоритм  запускался из 10 начальных приближений, одинаковых для всех запусков, и сравнивались средние значения целевых метрик.

\subsection{Особенности реализации}
Во-первых, требовалось обеспечить условие, что $\phi$ и $\theta$ отделимы от нуля. Однако было замечено, что в матрицах $\Phi$ и $\Theta$ некоторые элементы стремятся к нулю, но обнуляются посредством машинной точности только спустя очень много итераций. Поэтому при выполнении М-шага мы производили очень слабое разреживание. То есть, $n_{wt}$ и $n_{td}$ меньшие $10^{-6}$ занулялись. Формально, такое воздействие можно задать регуляризатором, мы говорили об этом в главе про неограниченные регуляризаторы.\\
Во-вторых, из-за ошибок округления возникали граничные эффекты при вычислении логарифма правдоподобия, поэтому при вычислении логарифмов в формуле мы использовали $\log(x + \varepsilon)$, где $\varepsilon$ --  маленькая константна равная $10^{-20}$. Таким образом , логарифм правдоподобия не устремлялся к минус бесконечности в плохих точках, но становился достаточно малым, чтобы заметить такой эффект. Фактически размером этой константы определяется в окрестности какого числа будут получаться  значения логарифма правдоподобия.
\subsection{Результаты}

	\section{Заключение и выводы}
	Нами было 
	\section{Благодарности}
	Хотим выразить особую благодарность 
\newpage
	\begin{thebibliography}{@@@@}
	\bibitem{plsadef1}
		Scott Deerwester, Susan T. Dumais, George W. Furnas, Thomas K. Landauer, Richard Harshman. Indexing by Latent Semantic Analysis,  JASIS (41), 1990.
	\bibitem{plsadef2}
		Thomas Hofmann. Probilistic latent semantic analysis, Proceedings of the Twenty-Second Annual International SIGIR Conference on Research and Development in Information Retrieval, 1999.
	\bibitem{ldadef1}
		David M. Blei, Andrew Ng, Michael Jordan. Latent Dirichlet allocation, Journal of Machine Learning Research,  2003
	\bibitem{artmdef1}
		Vorontsov K. V. Additive Regularization for Topic Models of Text Collections, Doklady Mathematics, 2014.
	\bibitem{artmdef2}
		Vorontsov K. V., Potapenko A. A. Tutorial on Probabilistic Topic Modeling: Additive Regularization for Stochastic Matrix Factorization,  AIST’2014, Analysis of Images, Social networks and Texts. Springer International Publishing Switzerland, 2014.
	\bibitem{artmdef3}
		Vorontsov K. V., Potapenko A. A. Additive Regularization of Topic Models, Machine Learning Journal, 2014.
	\bibitem{ldaonline1}
		Hoffman M. D., Blei D. M., Bach F. R. Online learning for latent dirichlet allocation, NIPS, Curran Associates, Inc., 2010.
	\bibitem{wuem}
		C. F. Jeff Wu. On the Convergence Properties of the EM Algorithm, The Annals of Statistics, 1983
	\bibitem{pinsker}
		F. Topsøe. Some inequalities for information divergence and related measures of discrimination. IEEE Transactions on Information Theory, 46(9):1602–1609, 2000
	\end{thebibliography}
\end{document}