{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимальные питоновские реализация оптимизации ARTM\n",
    "\n",
    "# + Формулы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.core.umath_tests import inner1d\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import gensim\n",
    "from collections import Counter\n",
    "import heapq\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разные функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogFunction(object):\n",
    "    def calc(self, x):\n",
    "        return np.log(x + 1e-20)\n",
    "    def calc_der(self, x):\n",
    "        return 1. / (x + 1e-20)\n",
    "    \n",
    "\n",
    "class IdFunction(object):\n",
    "    def calc(self, x):\n",
    "        return x + 1e-20\n",
    "    def calc_der(self, x):\n",
    "        return np.ones_like(x)\n",
    "    \n",
    "\n",
    "class SquareFunction(object):\n",
    "    def calc(self, x):\n",
    "        return (x + 1e-20) ** 2\n",
    "    def calc_der(self, x):\n",
    "        return 2. * (x + 1e-20) ** 2\n",
    "    \n",
    "\n",
    "class CubeLogFunction(object):\n",
    "    def calc(self, x):\n",
    "        return np.log(x + 1e-20) ** 3\n",
    "    def calc_der(self, x):\n",
    "        return 3. * np.log(x + 1e-20) ** 2 / (x + 1e-20)\n",
    "    \n",
    "\n",
    "class SquareLogFunction(object):\n",
    "    def calc(self, x):\n",
    "        return np.log(x + 1e-20) * np.abs(np.log(x + 1e-20))\n",
    "    def calc_der(self, x):\n",
    "        return 2. * np.abs(np.log(x + 1e-20)) / (x + 1e-20)\n",
    "\n",
    "    \n",
    "class FiveLogFunction(object):\n",
    "    def calc(self, x):\n",
    "        return np.log(x + 1e-20) ** 5\n",
    "    def calc_der(self, x):\n",
    "        return 5. * np.log(x + 1e-20) ** 4 / (x + 1e-20)\n",
    "    \n",
    "\n",
    "class CubeRootLogFunction(object):\n",
    "    def calc(self, x):\n",
    "        return np.cbrt(np.log(x + 1e-20))\n",
    "    def calc_der(self, x):\n",
    "        return 1. / 3 / (np.cbrt(np.log(x + 1e-20)) ** 2) / (x + 1e-20)\n",
    "    \n",
    "    \n",
    "class SquareRootLogFunction(object):\n",
    "    def calc(self, x):\n",
    "        return np.sqrt(- np.log(x + 1e-20))\n",
    "    def calc_der(self, x):\n",
    "        return 1. / 2. / np.sqrt(- np.log(x + 1e-20)) / (x + 1e-20)\n",
    "    \n",
    "\n",
    "class ExpFunction(object):\n",
    "    def calc(self, x):\n",
    "        return np.exp(x)\n",
    "    def calc_der(self, x):\n",
    "        return np.exp(x)\n",
    "\n",
    "    \n",
    "class EntropyFunction(object):\n",
    "    def calc(self, x):\n",
    "        return (np.log(x + 1e-20) + 50.) * (x + 1e-20)\n",
    "    def calc_der(self, x):\n",
    "        return np.log(x + 1e-20) + 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разные регуляризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trivial_regularization(n_tw, n_dt):\n",
    "    return 0., 0.\n",
    "\n",
    "def create_reg_decorr(tau, theta_alpha=0.):\n",
    "    def fun(n_tw, n_dt):\n",
    "        phi_matrix = n_tw / np.sum(n_tw, axis=1)[:, np.newaxis]\n",
    "        theta_matrix = n_dt / np.sum(n_dt, axis=1)[:, np.newaxis]\n",
    "        aggr_phi = np.sum(phi_matrix, axis=1)\n",
    "        return - tau * np.transpose(phi_matrix * (aggr_phi[:, np.newaxis] - phi_matrix)), theta_alpha\n",
    "    return fun\n",
    "\n",
    "def create_reg_lda(phi_alpha, theta_alpha):\n",
    "    def fun (n_tw, n_dt):\n",
    "        return phi_alpha, theta_alpha\n",
    "    return fun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка Датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно скачать некоторые коллекции данных и установить библиотеки (nltk, gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/tylorn/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset):\n",
    "    # remove stopwords\n",
    "    occurences = Counter()\n",
    "    for i, doc in enumerate(dataset.data):\n",
    "        tokens = gensim.utils.lemmatize(doc)\n",
    "        for token in set(tokens):\n",
    "            occurences[token] += 1\n",
    "        if i % 500 == 0:\n",
    "            print 'Processed: ', i, 'documents from', len(dataset.data)\n",
    "    \n",
    "    row, col, data = [], [], []\n",
    "    token_2_num = {}\n",
    "    not_empty_docs_number = 0\n",
    "    doc_targets = []\n",
    "    for doc, target in zip(dataset.data, dataset.target):\n",
    "        tokens = gensim.utils.lemmatize(doc)\n",
    "        cnt = Counter()\n",
    "        for token in tokens:\n",
    "            word = token.split('/')[0]\n",
    "            if word not in english_stopwords and 3 <= occurences[token]:\n",
    "                if token not in token_2_num:\n",
    "                    token_2_num[token] = len(token_2_num)\n",
    "                cnt[token_2_num[token]] += 1\n",
    "        \n",
    "        if len(cnt) > 0:\n",
    "            for w, c in cnt.iteritems():\n",
    "                row.append(not_empty_docs_number)\n",
    "                col.append(w)\n",
    "                data.append(c)\n",
    "            not_empty_docs_number += 1\n",
    "            doc_targets.append(target)\n",
    "        \n",
    "    num_2_token = {\n",
    "        v: k\n",
    "        for k, v in token_2_num.iteritems()\n",
    "    }\n",
    "    print 'Nonzero values:', len(data)\n",
    "    return scipy.sparse.csr_matrix((data, (row, col))), token_2_num, num_2_token, doc_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(\n",
    "    subset='all',\n",
    "    categories=['sci.electronics', 'sci.med', 'sci.space', 'sci.crypt', 'rec.sport.baseball', 'rec.sport.hockey'],\n",
    "    remove=('headers', 'footers', 'quotes')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed:  0 documents from 5945\n",
      "Processed:  500 documents from 5945\n",
      "Processed:  1000 documents from 5945\n",
      "Processed:  1500 documents from 5945\n",
      "Processed:  2000 documents from 5945\n",
      "Processed:  2500 documents from 5945\n",
      "Processed:  3000 documents from 5945\n",
      "Processed:  3500 documents from 5945\n",
      "Processed:  4000 documents from 5945\n",
      "Processed:  4500 documents from 5945\n",
      "Processed:  5000 documents from 5945\n",
      "Processed:  5500 documents from 5945\n",
      "Nonzero values: 322664\n",
      "CPU times: user 4min 26s, sys: 64 ms, total: 4min 26s\n",
      "Wall time: 4min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "origin_n_dw_matrix, token_2_num, num_2_token, doc_targets = prepare_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_dataset = fetch_20newsgroups(\n",
    "    subset='all',\n",
    "    remove=('headers', 'footers', 'quotes')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed:  0 documents from 18846\n",
      "Processed:  500 documents from 18846\n",
      "Processed:  1000 documents from 18846\n",
      "Processed:  1500 documents from 18846\n",
      "Processed:  2000 documents from 18846\n",
      "Processed:  2500 documents from 18846\n",
      "Processed:  3000 documents from 18846\n",
      "Processed:  3500 documents from 18846\n",
      "Processed:  4000 documents from 18846\n",
      "Processed:  4500 documents from 18846\n",
      "Processed:  5000 documents from 18846\n",
      "Processed:  5500 documents from 18846\n",
      "Processed:  6000 documents from 18846\n",
      "Processed:  6500 documents from 18846\n",
      "Processed:  7000 documents from 18846\n",
      "Processed:  7500 documents from 18846\n",
      "Processed:  8000 documents from 18846\n",
      "Processed:  8500 documents from 18846\n",
      "Processed:  9000 documents from 18846\n",
      "Processed:  9500 documents from 18846\n",
      "Processed:  10000 documents from 18846\n",
      "Processed:  10500 documents from 18846\n",
      "Processed:  11000 documents from 18846\n",
      "Processed:  11500 documents from 18846\n",
      "Processed:  12000 documents from 18846\n",
      "Processed:  12500 documents from 18846\n",
      "Processed:  13000 documents from 18846\n",
      "Processed:  13500 documents from 18846\n",
      "Processed:  14000 documents from 18846\n",
      "Processed:  14500 documents from 18846\n",
      "Processed:  15000 documents from 18846\n",
      "Processed:  15500 documents from 18846\n",
      "Processed:  16000 documents from 18846\n",
      "Processed:  16500 documents from 18846\n",
      "Processed:  17000 documents from 18846\n",
      "Processed:  17500 documents from 18846\n",
      "Processed:  18000 documents from 18846\n",
      "Processed:  18500 documents from 18846\n",
      "Nonzero values: 1071359\n",
      "CPU times: user 16min 16s, sys: 184 ms, total: 16min 16s\n",
      "Wall time: 16min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "big_origin_n_dw_matrix, _, _, big_doc_targets = prepare_dataset(big_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вычисление правдоподобных функций\n",
    "\n",
    "### имеется в виду вычисление функций вида $\\sum_{dw} n_{dw} f(\\sum_{t} \\phi_{wt} \\theta_{td})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_calculate_likelihood_like_function(n_dw_matrix, loss_function=LogFunction()):\n",
    "    D, W = n_dw_matrix.shape\n",
    "    docptr = []\n",
    "    indptr = n_dw_matrix.indptr\n",
    "    for doc_num in xrange(D):\n",
    "        docptr.extend([doc_num] * (indptr[doc_num + 1] - indptr[doc_num]))\n",
    "    docptr = np.array(docptr)\n",
    "    wordptr = n_dw_matrix.indices\n",
    "    \n",
    "    def fun(phi_matrix, theta_matrix):\n",
    "        s_data = loss_function.calc(inner1d(theta_matrix[docptr, :], np.transpose(phi_matrix)[wordptr, :]))\n",
    "        return np.sum(n_dw_matrix.data * s_data)\n",
    "\n",
    "    return fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общая схема:\n",
    "#### Неоходимо сначала вычислить $p_{tdw} = \\frac{\\phi_{wt} \\theta_{td}}{\\sum_s \\phi_{ws} \\theta_{sd}}$\n",
    "#### Считаем $n_{wt} = \\sum_d n_{dw} p_{tdw}$ и $n_{td} = \\sum_w n_{dw} p_{tdw}$\n",
    "#### Вычисляем $r_{wt}, r_{td}$ как функцию от $n_{wt}, n_{td}$\n",
    "#### Прибавляем, делаем положительную срезку и нормируем\n",
    "\n",
    "## Оптимизация вычисления:\n",
    "#### Обозначим за $s_{dw}$ следующее выражение $\\sum_t \\phi_{wt} \\theta_{td}$, фактически это наше предсказание для вероятности\n",
    "####  Тогда $p_{tdw} = \\frac{\\phi_{wt} \\theta_{td}}{s_{dw}}$\n",
    "#### Подставим это выражение например в $n_wt$\n",
    "#### И получим, что $n_{wt} = \\sum_d n_{dw} \\frac{\\phi_{wt} \\theta_{td}}{s_{dw}} = \\phi_{wt} \\sum_d \\theta_{td} \\cdot \\frac{n_{dw}}{s_{dw}}$, аналогично $n_{td} = \\theta_{td} \\sum_w \\phi_{wt} \\cdot \\frac{n_{dw}}{s_{dw}}$\n",
    "#### Таким образом, мы видим, что фактически нам нужно знать матрицу $\\frac{n_{dw}}{s_{dw}}$, а она очень разреженная, поэтому и $s_{dw}$ нужно не для всех пар вычислять, а только там, где $n_{dw} > 0$. \n",
    "#### То есть нам нужно эффективно закодить вычисление разженной матрицы $s_{dw}$ (матрица $n_{dw}$ уже есть в разреженном виде, так как подаётся на вход алгоритма), а затем просто поэлементно поделить\n",
    "#### Причём хочется, чтобы промежуточные значения $p_{tdw}$ не сохранялись (как мы увидели, они в конечном варианте не важны)\n",
    "#### Обозначим эту матрицу за $A$. Тогда $n_{wt} = \\phi_{wt} (\\Theta A)_{tw}$, а $n_{td} = \\theta_{td} (A \\Phi^T)_{dt}$.\n",
    "#### Перемножить разреженную матрицу на плотную можно быстро, если правильно её хранить (по строкам, или по столбцам)\n",
    "#### Если оптимизируется не правдоподобие, какая-то другая функция вида $\\sum_{dw} n_{dw} f(s_{dw})$ (правдоподобие будет, если $f(x) = \\ln x$ ) , то в этом случае нужно определить матрицу $A$ как $A_{dw} = n_{dw} f'(s_{dw})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def em_optimization(\n",
    "    n_dw_matrix, \n",
    "    phi_matrix,\n",
    "    theta_matrix,\n",
    "    regularization_list,\n",
    "    iters_count=100,\n",
    "    loss_function=LogFunction(),\n",
    "    iteration_callback=None\n",
    "):\n",
    "    D, W = n_dw_matrix.shape\n",
    "    T = phi_matrix.shape[0]\n",
    "    phi_matrix = np.copy(phi_matrix)\n",
    "    theta_matrix = np.copy(theta_matrix)\n",
    "    docptr = []\n",
    "    indptr = n_dw_matrix.indptr\n",
    "    for doc_num in xrange(D):\n",
    "        docptr.extend([doc_num] * (indptr[doc_num + 1] - indptr[doc_num]))\n",
    "    docptr = np.array(docptr)\n",
    "    wordptr = n_dw_matrix.indices\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for it in xrange(iters_count):\n",
    "        phi_matrix_tr = np.transpose(phi_matrix)\n",
    "        # следующая строчка это 60% времени работы алгоритма\n",
    "        s_data = loss_function.calc_der(inner1d(theta_matrix[docptr, :], phi_matrix_tr[wordptr, :]))\n",
    "        # следующая часть это 25% времени работы алгоритма\n",
    "        A = scipy.sparse.csr_matrix(\n",
    "            (\n",
    "                n_dw_matrix.data * s_data, \n",
    "                n_dw_matrix.indices, \n",
    "                n_dw_matrix.indptr\n",
    "            ), \n",
    "            shape=n_dw_matrix.shape\n",
    "        )\n",
    "        A_tr = A.tocsc().transpose()\n",
    "        # Остальное это 15% времени\n",
    "        n_tw = np.transpose(A_tr.dot(theta_matrix)) * phi_matrix\n",
    "        n_dt = A.dot(phi_matrix_tr) * theta_matrix\n",
    "        \n",
    "        r_tw, r_dt = regularization_list[it](n_tw, n_dt)\n",
    "        n_tw += r_tw\n",
    "        n_dt += n_dt\n",
    "        n_tw[n_tw < 0] = 0\n",
    "        n_dt[n_dt < 0] = 0\n",
    "        \n",
    "        phi_matrix = n_tw / np.sum(n_tw, axis=1)[:, np.newaxis]\n",
    "        theta_matrix = n_dt / np.sum(n_dt, axis=1)[:, np.newaxis]\n",
    "        \n",
    "        if iteration_callback is not None:\n",
    "            iteration_callback(it, phi_matrix, theta_matrix)\n",
    "    \n",
    "    print 'Iters time', time.time() - start_time\n",
    "    return phi_matrix, theta_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive thetaless EM\n",
    "\n",
    "\n",
    "### Основная идея: давайте вообще не хранить $\\Theta$, а вместо этого вычислять её на лету одной итерацией ЕМ алгоритма, которую можно легко выписать.\n",
    "\n",
    "##### Пусть тематический профиль документа инициализирован равномерно, то для этого документа $p_{tdw} = \\frac{\\phi_{wt}}{\\sum_s \\phi_s} \\equiv \\overline{\\phi}_{wt} \\equiv (\\overline{\\Phi})_{wt} \\equiv p(t~|~w)$ . Эту матрицу легко рассчитать.\n",
    "##### На первой итерации  будет подсчитано $n_{td} = \\sum_{d} n_{dw} p_{tdw} = \\sum_{d} n_{dw} (\\overline{\\Phi})_{wt} = (N\\overline{\\Phi})_{dt}$\n",
    "##### И, соответственно, $\\theta_{td} = \\frac{n_{td}}{\\sum_t n_{td}} =  \\frac{n_{td}}{n_d}$\n",
    "##### Введём матрицу $B_{dw} \\equiv \\frac{n_{dw}}{n_d}$, тогда $\\Theta = B \\Phi^T$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_thetaless_em_optimization(\n",
    "    n_dw_matrix, \n",
    "    phi_matrix,\n",
    "    regularization_list,\n",
    "    iters_count=100,\n",
    "    iteration_callback=None\n",
    "):\n",
    "    D, W = n_dw_matrix.shape\n",
    "    T = phi_matrix.shape[0]\n",
    "    phi_matrix = np.copy(phi_matrix)\n",
    "    docptr = []\n",
    "    indptr = n_dw_matrix.indptr\n",
    "    for doc_num in xrange(D):\n",
    "        docptr.extend([doc_num] * (indptr[doc_num + 1] - indptr[doc_num]))\n",
    "    docptr = np.array(docptr)\n",
    "    wordptr = n_dw_matrix.indices\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for it in xrange(iters_count):\n",
    "        phi_rev_matrix = np.transpose(phi_matrix / np.sum(phi_matrix, axis=0))\n",
    "        theta_matrix = n_dw_matrix.dot(phi_rev_matrix)\n",
    "        theta_matrix /= np.sum(theta_matrix, axis=1)[:, np.newaxis]\n",
    "        phi_matrix_tr = np.transpose(phi_matrix)\n",
    "        \n",
    "        s_data = 1. / inner1d(theta_matrix[docptr, :], phi_matrix_tr[wordptr, :])\n",
    "        A = scipy.sparse.csr_matrix(\n",
    "            (\n",
    "                n_dw_matrix.data  * s_data , \n",
    "                n_dw_matrix.indices, \n",
    "                n_dw_matrix.indptr\n",
    "            ), \n",
    "            shape=n_dw_matrix.shape\n",
    "        ).tocsc()\n",
    "            \n",
    "        n_tw = (A.T.dot(theta_matrix)).T * phi_matrix\n",
    "        r_tw, _ = regularization_list[it](n_tw, theta_matrix)\n",
    "        n_tw += r_tw\n",
    "        n_tw[n_tw < 0] = 0\n",
    "        phi_matrix = n_tw / np.sum(n_tw, axis=1)[:, np.newaxis]\n",
    "\n",
    "        if iteration_callback is not None:\n",
    "            iteration_callback(it, phi_matrix, theta_matrix)\n",
    "    \n",
    "    print 'Iters time', time.time() - start_time    \n",
    "    return phi_matrix, theta_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARTM thetaless EM optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def artm_thetaless_em_optimization(\n",
    "    n_dw_matrix, \n",
    "    phi_matrix,\n",
    "    iters_count=100,\n",
    "    iteration_callback=None\n",
    "):\n",
    "    D, W = n_dw_matrix.shape\n",
    "    T = phi_matrix.shape[0]\n",
    "    phi_matrix = np.copy(phi_matrix)\n",
    "    docptr = []\n",
    "    docsizes = []\n",
    "    indptr = n_dw_matrix.indptr\n",
    "    for doc_num in xrange(D):\n",
    "        size = indptr[doc_num + 1] - indptr[doc_num]\n",
    "        docptr.extend([doc_num] * size)\n",
    "        docsizes.extend([size] * size)\n",
    "    docptr = np.array(docptr)\n",
    "    wordptr = n_dw_matrix.indices\n",
    "    docsizes = np.array(docsizes)\n",
    "    \n",
    "    B = scipy.sparse.csr_matrix(\n",
    "        (\n",
    "            1. * n_dw_matrix.data  / docsizes, \n",
    "            n_dw_matrix.indices, \n",
    "            n_dw_matrix.indptr\n",
    "        ), \n",
    "        shape=n_dw_matrix.shape\n",
    "    ).tocsc()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for it in xrange(iters_count):\n",
    "        word_norm = np.sum(phi_matrix, axis=0)\n",
    "        phi_rev_matrix = np.transpose(phi_matrix / word_norm)\n",
    "        \n",
    "        theta_matrix = n_dw_matrix.dot(phi_rev_matrix)\n",
    "        theta_matrix /= np.sum(theta_matrix, axis=1)[:, np.newaxis]\n",
    "        phi_matrix_tr = np.transpose(phi_matrix)\n",
    "        \n",
    "        s_data = 1. / inner1d(theta_matrix[docptr, :], phi_matrix_tr[wordptr, :])\n",
    "        A = scipy.sparse.csr_matrix(\n",
    "            (\n",
    "                n_dw_matrix.data  * s_data , \n",
    "                n_dw_matrix.indices, \n",
    "                n_dw_matrix.indptr\n",
    "            ), \n",
    "            shape=n_dw_matrix.shape\n",
    "        ).tocsc()\n",
    "            \n",
    "        n_tw = A.T.dot(theta_matrix).T * phi_matrix\n",
    "        g_dt = A.dot(phi_matrix_tr)\n",
    "        tmp = g_dt.T * B\n",
    "        r_tw = (tmp / word_norm - np.einsum('ij,ji->i', phi_matrix_tr, tmp) / (word_norm ** 2)) * phi_matrix\n",
    "        \n",
    "        n_tw += r_tw\n",
    "        n_tw[n_tw < 0] = 0\n",
    "        phi_matrix = n_tw / np.sum(n_tw, axis=1)[:, np.newaxis]\n",
    "\n",
    "        if iteration_callback is not None:\n",
    "            iteration_callback(it, phi_matrix, theta_matrix)\n",
    "    \n",
    "    print 'Iters time', time.time() - start_time    \n",
    "    return phi_matrix, theta_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_optimization(\n",
    "    n_dw_matrix, \n",
    "    phi_matrix,\n",
    "    theta_matrix,\n",
    "    regularization_gradient_list,\n",
    "    iters_count=100,\n",
    "    loss_function=LogFunction(),\n",
    "    iteration_callback=None,\n",
    "    learning_rate=1.\n",
    "):\n",
    "    D, W = n_dw_matrix.shape\n",
    "    T = phi_matrix.shape[0]\n",
    "    phi_matrix = np.copy(phi_matrix)\n",
    "    theta_matrix = np.copy(theta_matrix)\n",
    "    docptr = []\n",
    "    indptr = n_dw_matrix.indptr\n",
    "    for doc_num in xrange(D):\n",
    "        docptr.extend([doc_num] * (indptr[doc_num + 1] - indptr[doc_num]))\n",
    "    docptr = np.array(docptr)\n",
    "    wordptr = n_dw_matrix.indices\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for it in xrange(iters_count):\n",
    "        phi_matrix_tr = np.transpose(phi_matrix)\n",
    "        # следующая строчка это 60% времени работы алгоритма\n",
    "        s_data = loss_function.calc_der(inner1d(theta_matrix[docptr, :], phi_matrix_tr[wordptr, :]))\n",
    "        # следующая часть это 25% времени работы алгоритма\n",
    "        A = scipy.sparse.csr_matrix(\n",
    "            (\n",
    "                n_dw_matrix.data * s_data, \n",
    "                n_dw_matrix.indices, \n",
    "                n_dw_matrix.indptr\n",
    "            ), \n",
    "            shape=n_dw_matrix.shape\n",
    "        ).tocsc()\n",
    "        # Остальное это 15% времени\n",
    "        g_tw = theta_matrix.T * A\n",
    "        g_dt = A.dot(phi_matrix_tr)\n",
    "        \n",
    "        r_tw, r_dt = regularization_gradient_list[it](phi_matrix, theta_matrix)\n",
    "        g_tw += r_tw\n",
    "        g_dt += r_dt\n",
    "        \n",
    "        g_tw -= np.sum(g_tw * phi_matrix, axis=1)[:, np.newaxis]\n",
    "        g_dt -= np.sum(g_dt * theta_matrix, axis=1)[:, np.newaxis]\n",
    "        \n",
    "        phi_matrix += g_tw * learning_rate\n",
    "        theta_matrix += g_dt * learning_rate\n",
    "        \n",
    "        phi_matrix[phi_matrix < 0] = 0\n",
    "        theta_matrix[theta_matrix < 0] = 0\n",
    "        \n",
    "        phi_matrix /= np.sum(phi_matrix, axis=1)[:, np.newaxis]\n",
    "        theta_matrix /= np.sum(theta_matrix, axis=1)[:, np.newaxis]\n",
    "        \n",
    "        if iteration_callback is not None:\n",
    "            iteration_callback(it, phi_matrix, theta_matrix)\n",
    "    \n",
    "    print 'Iters time', time.time() - start_time  \n",
    "    return phi_matrix, theta_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Оценка качества классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_score(theta, targets):\n",
    "    C_2d_range = [1e0, 1e1, 1e2, 1e3, 1e4]\n",
    "    gamma_2d_range = [1e-3, 1e-2, 1e-1, 1, 1e1]\n",
    "    for C in C_2d_range:\n",
    "        for gamma in gamma_2d_range:\n",
    "            print 'SVM(C={}, gamma={}) score: {}'.format(\n",
    "                C,\n",
    "                gamma,\n",
    "                np.mean(cross_val_score(SVC(C=C, gamma=gamma), theta, targets, scoring='accuracy', cv=4))\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Примеры запусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLSA: EM optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3986.0704926\n",
      "1 3906.19009155\n",
      "2 3816.50258883\n",
      "3 3706.06393687\n",
      "4 3572.34675498\n",
      "5 3422.22011816\n",
      "6 3268.08384344\n",
      "7 3119.83183247\n",
      "8 2983.70125846\n",
      "9 2863.18846394\n",
      "10 2759.69951822\n",
      "11 2672.42541819\n",
      "12 2599.05123244\n",
      "13 2536.97312372\n",
      "14 2483.83221649\n",
      "15 2437.75378852\n",
      "16 2397.31633049\n",
      "17 2361.2891356\n",
      "18 2328.82670318\n",
      "19 2299.34993209\n",
      "20 2272.58561051\n",
      "21 2248.73220363\n",
      "22 2227.65996306\n",
      "23 2208.70765597\n",
      "24 2191.35635596\n",
      "25 2174.89348508\n",
      "26 2159.11967244\n",
      "27 2144.42764304\n",
      "28 2131.28250351\n",
      "29 2119.31240838\n",
      "30 2108.36589959\n",
      "31 2098.46248252\n",
      "32 2089.30733262\n",
      "33 2081.12016961\n",
      "34 2073.44101797\n",
      "35 2066.20339851\n",
      "36 2059.38450385\n",
      "37 2053.0078317\n",
      "38 2046.96650212\n",
      "39 2041.17463077\n",
      "40 2035.4610121\n",
      "41 2029.96956402\n",
      "42 2024.71547536\n",
      "43 2019.67900783\n",
      "44 2014.82612812\n",
      "45 2010.11252984\n",
      "46 2005.54425925\n",
      "47 2001.10582942\n",
      "48 1996.92925567\n",
      "49 1993.06135312\n",
      "50 1989.37842384\n",
      "51 1985.82831163\n",
      "52 1982.42779562\n",
      "53 1979.20828384\n",
      "54 1976.22776342\n",
      "55 1973.49514204\n",
      "56 1970.91173228\n",
      "57 1968.36860342\n",
      "58 1965.85370816\n",
      "59 1963.40595461\n",
      "60 1961.12623071\n",
      "61 1958.965441\n",
      "62 1956.93703538\n",
      "63 1955.07347686\n",
      "64 1953.29567494\n",
      "65 1951.60438027\n",
      "66 1950.02060316\n",
      "67 1948.48911878\n",
      "68 1946.96359044\n",
      "69 1945.45878197\n",
      "70 1944.01738116\n",
      "71 1942.59535662\n",
      "72 1941.20357724\n",
      "73 1939.88246022\n",
      "74 1938.63416694\n",
      "75 1937.42081995\n",
      "76 1936.21654796\n",
      "77 1935.00300288\n",
      "78 1933.79669128\n",
      "79 1932.69144487\n",
      "80 1931.70716259\n",
      "81 1930.77261384\n",
      "82 1929.83407443\n",
      "83 1928.87729396\n",
      "84 1927.90589349\n",
      "85 1926.92901065\n",
      "86 1925.96649274\n",
      "87 1925.04324945\n",
      "88 1924.17951915\n",
      "89 1923.37279385\n",
      "90 1922.60043027\n",
      "91 1921.86880874\n",
      "92 1921.20305105\n",
      "93 1920.57121616\n",
      "94 1919.95984756\n",
      "95 1919.36367202\n",
      "96 1918.76684653\n",
      "97 1918.13890455\n",
      "98 1917.52405437\n",
      "99 1916.96283418\n",
      "100 1916.45127549\n",
      "101 1915.94582385\n",
      "102 1915.41791624\n",
      "103 1914.87795757\n",
      "104 1914.36691098\n",
      "105 1913.87040349\n",
      "106 1913.3417976\n",
      "107 1912.7771315\n",
      "108 1912.2438752\n",
      "109 1911.7919402\n",
      "110 1911.39811781\n",
      "111 1911.01409667\n",
      "112 1910.62369642\n",
      "113 1910.23432361\n",
      "114 1909.85375106\n",
      "115 1909.47392237\n",
      "116 1909.08976778\n",
      "117 1908.69857866\n",
      "118 1908.30326462\n",
      "119 1907.93751198\n",
      "120 1907.55970561\n",
      "121 1907.16402885\n",
      "122 1906.78669467\n",
      "123 1906.43157718\n",
      "124 1906.10215469\n",
      "125 1905.77739551\n",
      "126 1905.4244275\n",
      "127 1905.01930252\n",
      "128 1904.63587106\n",
      "129 1904.30411033\n",
      "130 1903.99205957\n",
      "131 1903.68301703\n",
      "132 1903.38326979\n",
      "133 1903.09501518\n",
      "134 1902.81747478\n",
      "135 1902.53624886\n",
      "136 1902.26401867\n",
      "137 1902.01330198\n",
      "138 1901.75978845\n",
      "139 1901.50139585\n",
      "140 1901.24865034\n",
      "141 1901.00144628\n",
      "142 1900.75927394\n",
      "143 1900.50200169\n",
      "144 1900.23109194\n",
      "145 1899.97800091\n",
      "146 1899.74512701\n",
      "147 1899.52893752\n",
      "148 1899.33209265\n",
      "149 1899.12498819\n",
      "150 1898.90574629\n",
      "151 1898.67777345\n",
      "152 1898.43134601\n",
      "153 1898.18250722\n",
      "154 1897.96597963\n",
      "155 1897.77710366\n",
      "156 1897.60104738\n",
      "157 1897.43079496\n",
      "158 1897.25589949\n",
      "159 1897.07352998\n",
      "160 1896.89551033\n",
      "161 1896.72525175\n",
      "162 1896.5563074\n",
      "163 1896.37900209\n",
      "164 1896.18935635\n",
      "165 1896.00286627\n",
      "166 1895.82824747\n",
      "167 1895.6540718\n",
      "168 1895.46985361\n",
      "169 1895.28053979\n",
      "170 1895.09864015\n",
      "171 1894.93347114\n",
      "172 1894.78400876\n",
      "173 1894.64465059\n",
      "174 1894.50665621\n",
      "175 1894.36657517\n",
      "176 1894.2320339\n",
      "177 1894.10065722\n",
      "178 1893.97238464\n",
      "179 1893.83994688\n",
      "180 1893.69469621\n",
      "181 1893.52839492\n",
      "182 1893.33139332\n",
      "183 1893.11782204\n",
      "184 1892.91003881\n",
      "185 1892.7030789\n",
      "186 1892.51973988\n",
      "187 1892.35158939\n",
      "188 1892.17491746\n",
      "189 1891.98550762\n",
      "190 1891.79363223\n",
      "191 1891.60354794\n",
      "192 1891.41583659\n",
      "193 1891.23868735\n",
      "194 1891.0882744\n",
      "195 1890.95542954\n",
      "196 1890.82740356\n",
      "197 1890.69758296\n",
      "198 1890.57140675\n",
      "199 1890.44755589\n",
      "Iters time 22.1648659706\n",
      "Iters time 13.1041109562\n"
     ]
    }
   ],
   "source": [
    "D, W = origin_n_dw_matrix.shape\n",
    "T = 10\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_matrix = np.random.uniform(size=(T, W)).astype(np.float64)\n",
    "phi_matrix /= np.sum(phi_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "theta_matrix = np.random.uniform(size=(D, T)).astype(np.float64)\n",
    "theta_matrix /= np.sum(theta_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "regularization_list = np.zeros(200, dtype=object)\n",
    "regularization_list[:] = trivial_regularization\n",
    "\n",
    "calc_log_likelihood = create_calculate_likelihood_like_function(\n",
    "    loss_function=LogFunction(),\n",
    "    n_dw_matrix=origin_n_dw_matrix\n",
    ")\n",
    "\n",
    "total_words_number = origin_n_dw_matrix.sum()\n",
    "def callback(it, phi, theta):\n",
    "    print it,  np.exp(- calc_log_likelihood(phi, theta) / total_words_number)\n",
    "\n",
    "phi, theta = em_optimization(\n",
    "    n_dw_matrix=origin_n_dw_matrix, \n",
    "    phi_matrix=phi_matrix,\n",
    "    theta_matrix=theta_matrix,\n",
    "    regularization_list=regularization_list,\n",
    "    iters_count=200,\n",
    "    loss_function=LogFunction(),\n",
    "    iteration_callback=callback\n",
    ")\n",
    "\n",
    "phi, theta = em_optimization(\n",
    "    n_dw_matrix=origin_n_dw_matrix, \n",
    "    phi_matrix=phi_matrix,\n",
    "    theta_matrix=theta_matrix,\n",
    "    regularization_list=regularization_list,\n",
    "    iters_count=200,\n",
    "    loss_function=LogFunction()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi_plsa_em = phi\n",
    "theta_plsa_em = theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.672531979977753"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. * np.sum(phi < 1e-20) / np.sum(phi >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(C=1.0, gamma=0.001) score: 0.520351804446\n",
      "SVM(C=1.0, gamma=0.01) score: 0.681636535081\n",
      "SVM(C=1.0, gamma=0.1) score: 0.722342929618\n",
      "SVM(C=1.0, gamma=1) score: 0.744088708797\n",
      "SVM(C=1.0, gamma=10.0) score: 0.745307372089\n",
      "SVM(C=10.0, gamma=0.001) score: 0.681113886998\n",
      "SVM(C=10.0, gamma=0.01) score: 0.722341961247\n",
      "SVM(C=10.0, gamma=0.1) score: 0.742002348356\n",
      "SVM(C=10.0, gamma=1) score: 0.750695724108\n",
      "SVM(C=10.0, gamma=10.0) score: 0.732265501282\n",
      "SVM(C=100.0, gamma=0.001) score: 0.722167745219\n",
      "SVM(C=100.0, gamma=0.01) score: 0.738346111969\n",
      "SVM(C=100.0, gamma=0.1) score: 0.748613120209\n",
      "SVM(C=100.0, gamma=1) score: 0.749136975602\n",
      "SVM(C=100.0, gamma=10.0) score: 0.711388382576\n",
      "SVM(C=1000.0, gamma=0.001) score: 0.738520932913\n",
      "SVM(C=1000.0, gamma=0.01) score: 0.745133034069\n",
      "SVM(C=1000.0, gamma=0.1) score: 0.750003457869\n",
      "SVM(C=1000.0, gamma=1) score: 0.746527606146\n",
      "SVM(C=1000.0, gamma=10.0) score: 0.693119555581\n",
      "SVM(C=10000.0, gamma=0.001) score: 0.742871855207\n",
      "SVM(C=10000.0, gamma=0.01) score: 0.748264688153\n",
      "SVM(C=10000.0, gamma=0.1) score: 0.748786367865\n",
      "SVM(C=10000.0, gamma=1) score: 0.731041991084\n",
      "SVM(C=10000.0, gamma=10.0) score: 0.683894938393\n"
     ]
    }
   ],
   "source": [
    "svm_score(theta, doc_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA: EM optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3987.37646827\n",
      "1 3897.4074752\n",
      "2 3798.04728921\n",
      "3 3680.90916256\n",
      "4 3546.86075721\n",
      "5 3404.40082914\n",
      "6 3264.35983653\n",
      "7 3133.42614365\n",
      "8 3015.05899483\n",
      "9 2911.23100587\n",
      "10 2822.68526189\n",
      "11 2748.84376085\n",
      "12 2687.63946797\n",
      "13 2636.38528098\n",
      "14 2592.68187264\n",
      "15 2555.07686584\n",
      "16 2523.26596425\n",
      "17 2497.10117303\n",
      "18 2475.8452058\n",
      "19 2458.50015838\n",
      "20 2444.08698345\n",
      "21 2431.83457879\n",
      "22 2421.18913973\n",
      "23 2411.9411239\n",
      "24 2403.92060151\n",
      "25 2396.88272169\n",
      "26 2390.67929499\n",
      "27 2385.21190858\n",
      "28 2380.39755883\n",
      "29 2376.12819046\n",
      "30 2372.32169245\n",
      "31 2368.94321943\n",
      "32 2365.92689874\n",
      "33 2363.16733183\n",
      "34 2360.63018304\n",
      "35 2358.32615751\n",
      "36 2356.24209776\n",
      "37 2354.33902549\n",
      "38 2352.5797764\n",
      "39 2350.94714679\n",
      "40 2349.42551463\n",
      "41 2348.00372283\n",
      "42 2346.66906665\n",
      "43 2345.42598409\n",
      "44 2344.2645335\n",
      "45 2343.1731887\n",
      "46 2342.13828756\n",
      "47 2341.14797914\n",
      "48 2340.19949656\n",
      "49 2339.29619816\n",
      "50 2338.44005861\n",
      "51 2337.62109798\n",
      "52 2336.83933634\n",
      "53 2336.09686008\n",
      "54 2335.38957787\n",
      "55 2334.70918016\n",
      "56 2334.04792875\n",
      "57 2333.42233786\n",
      "58 2332.83523389\n",
      "59 2332.27917001\n",
      "60 2331.75305196\n",
      "61 2331.25271696\n",
      "62 2330.77615874\n",
      "63 2330.33010407\n",
      "64 2329.9150551\n",
      "65 2329.52089968\n",
      "66 2329.14322494\n",
      "67 2328.78287141\n",
      "68 2328.44216167\n",
      "69 2328.12517492\n",
      "70 2327.82241853\n",
      "71 2327.5418305\n",
      "72 2327.28474822\n",
      "73 2327.04402804\n",
      "74 2326.81553894\n",
      "75 2326.60272005\n",
      "76 2326.40562719\n",
      "77 2326.22119101\n",
      "78 2326.04750722\n",
      "79 2325.87940292\n",
      "80 2325.71403989\n",
      "81 2325.54838716\n",
      "82 2325.38345598\n",
      "83 2325.21904186\n",
      "84 2325.06075757\n",
      "85 2324.90832362\n",
      "86 2324.75886924\n",
      "87 2324.61477147\n",
      "88 2324.48024014\n",
      "89 2324.3518429\n",
      "90 2324.22442069\n",
      "91 2324.10467562\n",
      "92 2323.99363126\n",
      "93 2323.8882548\n",
      "94 2323.78754344\n",
      "95 2323.6881951\n",
      "96 2323.58968282\n",
      "97 2323.49561163\n",
      "98 2323.40154587\n",
      "99 2323.3073218\n",
      "100 2323.21623718\n",
      "101 2323.131387\n",
      "102 2323.0527401\n",
      "103 2322.97873245\n",
      "104 2322.90705203\n",
      "105 2322.8371887\n",
      "106 2322.76968163\n",
      "107 2322.70323786\n",
      "108 2322.63449177\n",
      "109 2322.55920412\n",
      "110 2322.48739965\n",
      "111 2322.42325992\n",
      "112 2322.36022314\n",
      "113 2322.29867669\n",
      "114 2322.24079467\n",
      "115 2322.18437386\n",
      "116 2322.1273491\n",
      "117 2322.07313962\n",
      "118 2322.02334236\n",
      "119 2321.97659422\n",
      "120 2321.93133353\n",
      "121 2321.88651536\n",
      "122 2321.84136914\n",
      "123 2321.79557275\n",
      "124 2321.75014859\n",
      "125 2321.70511034\n",
      "126 2321.65801661\n",
      "127 2321.61019922\n",
      "128 2321.56611439\n",
      "129 2321.52545537\n",
      "130 2321.48717802\n",
      "131 2321.4508752\n",
      "132 2321.4157395\n",
      "133 2321.3815712\n",
      "134 2321.34876435\n",
      "135 2321.31850515\n",
      "136 2321.29044337\n",
      "137 2321.26345368\n",
      "138 2321.23523175\n",
      "139 2321.20800362\n",
      "140 2321.18570186\n",
      "141 2321.16511486\n",
      "142 2321.14301329\n",
      "143 2321.11840517\n",
      "144 2321.094345\n",
      "145 2321.07300953\n",
      "146 2321.05220663\n",
      "147 2321.03173697\n",
      "148 2321.01252794\n",
      "149 2320.99460846\n",
      "150 2320.97827487\n",
      "151 2320.96322912\n",
      "152 2320.94811306\n",
      "153 2320.93295492\n",
      "154 2320.91739542\n",
      "155 2320.9001958\n",
      "156 2320.87804102\n",
      "157 2320.84943973\n",
      "158 2320.82267776\n",
      "159 2320.79978337\n",
      "160 2320.78039855\n",
      "161 2320.76345968\n",
      "162 2320.74749676\n",
      "163 2320.73160032\n",
      "164 2320.71576767\n",
      "165 2320.69974005\n",
      "166 2320.68282179\n",
      "167 2320.66512145\n",
      "168 2320.64722048\n",
      "169 2320.6299356\n",
      "170 2320.61298627\n",
      "171 2320.59599604\n",
      "172 2320.57892294\n",
      "173 2320.56258844\n",
      "174 2320.54796558\n",
      "175 2320.53491176\n",
      "176 2320.5221391\n",
      "177 2320.50882887\n",
      "178 2320.49497395\n",
      "179 2320.48030399\n",
      "180 2320.464433\n",
      "181 2320.44664265\n",
      "182 2320.42617924\n",
      "183 2320.40450954\n",
      "184 2320.38385666\n",
      "185 2320.3647097\n",
      "186 2320.34707555\n",
      "187 2320.33002237\n",
      "188 2320.31278378\n",
      "189 2320.29536408\n",
      "190 2320.27959458\n",
      "191 2320.26553364\n",
      "192 2320.25259081\n",
      "193 2320.24069567\n",
      "194 2320.23016036\n",
      "195 2320.22002878\n",
      "196 2320.20936655\n",
      "197 2320.19732619\n",
      "198 2320.18152892\n",
      "199 2320.15559914\n",
      "Iters time 23.1285910606\n",
      "Iters time 12.1620118618\n"
     ]
    }
   ],
   "source": [
    "D, W = origin_n_dw_matrix.shape\n",
    "T = 10\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_matrix = np.random.uniform(size=(T, W)).astype(np.float64)\n",
    "phi_matrix /= np.sum(phi_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "theta_matrix = np.random.uniform(size=(D, T)).astype(np.float64)\n",
    "theta_matrix /= np.sum(theta_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "regularization_list = np.zeros(200, dtype=object)\n",
    "regularization_list[:] = create_reg_lda(-0.1, 0.)\n",
    "\n",
    "calc_log_likelihood = create_calculate_likelihood_like_function(\n",
    "    loss_function=LogFunction(),\n",
    "    n_dw_matrix=origin_n_dw_matrix\n",
    ")\n",
    "\n",
    "total_words_number = origin_n_dw_matrix.sum()\n",
    "def callback(it, phi, theta):\n",
    "    print it,  np.exp(- calc_log_likelihood(phi, theta) / total_words_number)\n",
    "\n",
    "phi, theta = em_optimization(\n",
    "    n_dw_matrix=origin_n_dw_matrix, \n",
    "    phi_matrix=phi_matrix,\n",
    "    theta_matrix=theta_matrix,\n",
    "    regularization_list=regularization_list,\n",
    "    iters_count=200,\n",
    "    loss_function=LogFunction(),\n",
    "    iteration_callback=callback\n",
    ")\n",
    "\n",
    "phi, theta = em_optimization(\n",
    "    n_dw_matrix=origin_n_dw_matrix, \n",
    "    phi_matrix=phi_matrix,\n",
    "    theta_matrix=theta_matrix,\n",
    "    regularization_list=regularization_list,\n",
    "    iters_count=200,\n",
    "    loss_function=LogFunction()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8196398776418242"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. * np.sum(phi < 1e-20) / np.sum(phi >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(C=1.0, gamma=0.001) score: 0.169276275902\n",
      "SVM(C=1.0, gamma=0.01) score: 0.600039134497\n",
      "SVM(C=1.0, gamma=0.1) score: 0.642485498488\n",
      "SVM(C=1.0, gamma=1) score: 0.670317711202\n",
      "SVM(C=1.0, gamma=10.0) score: 0.675196603837\n",
      "SVM(C=10.0, gamma=0.001) score: 0.599690702441\n",
      "SVM(C=10.0, gamma=0.01) score: 0.640049379212\n",
      "SVM(C=10.0, gamma=0.1) score: 0.661270332102\n",
      "SVM(C=10.0, gamma=1) score: 0.680413644943\n",
      "SVM(C=10.0, gamma=10.0) score: 0.650666639307\n",
      "SVM(C=100.0, gamma=0.001) score: 0.640223958695\n",
      "SVM(C=100.0, gamma=0.01) score: 0.660573589984\n",
      "SVM(C=100.0, gamma=0.1) score: 0.672237234086\n",
      "SVM(C=100.0, gamma=1) score: 0.677459353464\n",
      "SVM(C=100.0, gamma=10.0) score: 0.612393217468\n",
      "SVM(C=1000.0, gamma=0.001) score: 0.659530108567\n",
      "SVM(C=1000.0, gamma=0.01) score: 0.662487427154\n",
      "SVM(C=1000.0, gamma=0.1) score: 0.67293397368\n",
      "SVM(C=1000.0, gamma=1) score: 0.670677995083\n",
      "SVM(C=1000.0, gamma=10.0) score: 0.589072486595\n",
      "SVM(C=10000.0, gamma=0.001) score: 0.661096479529\n",
      "SVM(C=10000.0, gamma=0.01) score: 0.672932402916\n",
      "SVM(C=10000.0, gamma=0.1) score: 0.676940222984\n",
      "SVM(C=10000.0, gamma=1) score: 0.648232942222\n",
      "SVM(C=10000.0, gamma=10.0) score: 0.584021548565\n"
     ]
    }
   ],
   "source": [
    "svm_score(theta, doc_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLSA: naive thetaless EM optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4028.35177178\n",
      "1 4021.70284106\n",
      "2 4010.85417715\n",
      "3 3992.47680023\n",
      "4 3962.57281777\n",
      "5 3918.66130822\n",
      "6 3858.60944736\n",
      "7 3779.02320026\n",
      "8 3678.00890305\n",
      "9 3557.60111366\n",
      "10 3424.09415717\n",
      "11 3286.93928091\n",
      "12 3155.88858099\n",
      "13 3037.63331739\n",
      "14 2934.65975247\n",
      "15 2846.60272155\n",
      "16 2771.81820433\n",
      "17 2708.09139679\n",
      "18 2653.23728614\n",
      "19 2605.52734057\n",
      "20 2563.82805547\n",
      "21 2527.47902652\n",
      "22 2496.01808851\n",
      "23 2468.9673896\n",
      "24 2445.77497288\n",
      "25 2425.86697009\n",
      "26 2408.70801891\n",
      "27 2393.82768905\n",
      "28 2380.85744338\n",
      "29 2369.4991576\n",
      "30 2359.4620215\n",
      "31 2350.46863365\n",
      "32 2342.29522488\n",
      "33 2334.77867514\n",
      "34 2327.84692884\n",
      "35 2321.57292316\n",
      "36 2316.02284294\n",
      "37 2311.15125784\n",
      "38 2306.84215015\n",
      "39 2302.97900869\n",
      "40 2299.47429011\n",
      "41 2296.27278533\n",
      "42 2293.34037007\n",
      "43 2290.65809191\n",
      "44 2288.1943657\n",
      "45 2285.92025384\n",
      "46 2283.81069361\n",
      "47 2281.83589404\n",
      "48 2279.96375713\n",
      "49 2278.17297431\n",
      "50 2276.45806591\n",
      "51 2274.82519468\n",
      "52 2273.27885688\n",
      "53 2271.79915634\n",
      "54 2270.35432729\n",
      "55 2268.92474786\n",
      "56 2267.50940967\n",
      "57 2266.12473908\n",
      "58 2264.8033004\n",
      "59 2263.57547476\n",
      "60 2262.43447918\n",
      "61 2261.33310658\n",
      "62 2260.22047473\n",
      "63 2259.0903221\n",
      "64 2257.96101759\n",
      "65 2256.83874271\n",
      "66 2255.74521675\n",
      "67 2254.70174238\n",
      "68 2253.76309614\n",
      "69 2252.91418772\n",
      "70 2252.1212363\n",
      "71 2251.37574874\n",
      "72 2250.6781632\n",
      "73 2250.01692952\n",
      "74 2249.36162022\n",
      "75 2248.71555251\n",
      "76 2248.1167606\n",
      "77 2247.56261022\n",
      "78 2247.03423359\n",
      "79 2246.48713755\n",
      "80 2245.91441066\n",
      "81 2245.37865135\n",
      "82 2244.89223354\n",
      "83 2244.44893714\n",
      "84 2244.02867519\n",
      "85 2243.62336988\n",
      "86 2243.22301232\n",
      "87 2242.82077091\n",
      "88 2242.42242205\n",
      "89 2242.03119325\n",
      "90 2241.64829111\n",
      "91 2241.28264415\n",
      "92 2240.93548664\n",
      "93 2240.59965196\n",
      "94 2240.26755079\n",
      "95 2239.94095367\n",
      "96 2239.6256652\n",
      "97 2239.32183559\n",
      "98 2239.02224247\n",
      "99 2238.716948\n",
      "100 2238.40217407\n",
      "101 2238.08728305\n",
      "102 2237.78787429\n",
      "103 2237.50960317\n",
      "104 2237.24278027\n",
      "105 2236.98090701\n",
      "106 2236.72229518\n",
      "107 2236.46767647\n",
      "108 2236.21828153\n",
      "109 2235.97380234\n",
      "110 2235.73356301\n",
      "111 2235.49652073\n",
      "112 2235.26135444\n",
      "113 2235.02741108\n",
      "114 2234.79450022\n",
      "115 2234.56175527\n",
      "116 2234.32639705\n",
      "117 2234.08939873\n",
      "118 2233.85470982\n",
      "119 2233.62136025\n",
      "120 2233.38891019\n",
      "121 2233.15656698\n",
      "122 2232.9231479\n",
      "123 2232.68779968\n",
      "124 2232.45028639\n",
      "125 2232.21036679\n",
      "126 2231.96779937\n",
      "127 2231.72285228\n",
      "128 2231.47684817\n",
      "129 2231.23153111\n",
      "130 2230.98785929\n",
      "131 2230.74725272\n",
      "132 2230.51215753\n",
      "133 2230.28436543\n",
      "134 2230.06459559\n",
      "135 2229.85176648\n",
      "136 2229.64485444\n",
      "137 2229.44465981\n",
      "138 2229.25007571\n",
      "139 2229.05944287\n",
      "140 2228.87202927\n",
      "141 2228.688057\n",
      "142 2228.50885496\n",
      "143 2228.33487437\n",
      "144 2228.16495706\n",
      "145 2227.99770403\n",
      "146 2227.83174583\n",
      "147 2227.66570449\n",
      "148 2227.49845246\n",
      "149 2227.32962502\n",
      "150 2227.15982181\n",
      "151 2226.99001\n",
      "152 2226.82135836\n",
      "153 2226.65548329\n",
      "154 2226.49396745\n",
      "155 2226.33724801\n",
      "156 2226.18424926\n",
      "157 2226.03510207\n",
      "158 2225.89076192\n",
      "159 2225.75019544\n",
      "160 2225.61279323\n",
      "161 2225.47804918\n",
      "162 2225.34485407\n",
      "163 2225.2118399\n",
      "164 2225.07833947\n",
      "165 2224.94496374\n",
      "166 2224.81319548\n",
      "167 2224.68403679\n",
      "168 2224.5574279\n",
      "169 2224.43297978\n",
      "170 2224.31026179\n",
      "171 2224.18828572\n",
      "172 2224.06576209\n",
      "173 2223.94233065\n",
      "174 2223.81905572\n",
      "175 2223.69767209\n",
      "176 2223.57992084\n",
      "177 2223.46638781\n",
      "178 2223.35585515\n",
      "179 2223.24644079\n",
      "180 2223.13637673\n",
      "181 2223.02405341\n",
      "182 2222.90783064\n",
      "183 2222.78592832\n",
      "184 2222.65682103\n",
      "185 2222.51992854\n",
      "186 2222.37520847\n",
      "187 2222.22237253\n",
      "188 2222.06179103\n",
      "189 2221.89587045\n",
      "190 2221.72915928\n",
      "191 2221.56693031\n",
      "192 2221.41352883\n",
      "193 2221.27127966\n",
      "194 2221.14009183\n",
      "195 2221.01792295\n",
      "196 2220.9016561\n",
      "197 2220.78826488\n",
      "198 2220.67630503\n",
      "199 2220.56651773\n",
      "Iters time 22.5940768719\n",
      "Iters time 12.4394779205\n"
     ]
    }
   ],
   "source": [
    "D, W = origin_n_dw_matrix.shape\n",
    "T = 10\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_matrix = np.random.uniform(size=(T, W)).astype(np.float64)\n",
    "phi_matrix /= np.sum(phi_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "theta_matrix = np.random.uniform(size=(D, T)).astype(np.float64)\n",
    "theta_matrix /= np.sum(theta_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "regularization_list = np.zeros(200, dtype=object)\n",
    "regularization_list[:] = trivial_regularization\n",
    "\n",
    "calc_log_likelihood = create_calculate_likelihood_like_function(\n",
    "    loss_function=LogFunction(),\n",
    "    n_dw_matrix=origin_n_dw_matrix\n",
    ")\n",
    "\n",
    "total_words_number = origin_n_dw_matrix.sum()\n",
    "def callback(it, phi, theta):\n",
    "    print it,  np.exp(- calc_log_likelihood(phi, theta) / total_words_number)\n",
    "\n",
    "phi, theta = naive_thetaless_em_optimization(\n",
    "    n_dw_matrix=origin_n_dw_matrix, \n",
    "    phi_matrix=phi_matrix,\n",
    "    regularization_list=regularization_list,\n",
    "    iters_count=200,\n",
    "    iteration_callback=callback\n",
    ")\n",
    "\n",
    "phi, theta = naive_thetaless_em_optimization(\n",
    "    n_dw_matrix=origin_n_dw_matrix, \n",
    "    phi_matrix=phi_matrix,\n",
    "    regularization_list=regularization_list,\n",
    "    iters_count=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7207244160177976"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. * np.sum(phi < 1e-20) / np.sum(phi >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(C=1.0, gamma=0.001) score: 0.169276275902\n",
      "SVM(C=1.0, gamma=0.01) score: 0.805159600936\n",
      "SVM(C=1.0, gamma=0.1) score: 0.822387866773\n",
      "SVM(C=1.0, gamma=1) score: 0.832828722538\n",
      "SVM(C=1.0, gamma=10.0) score: 0.838566713923\n",
      "SVM(C=10.0, gamma=0.001) score: 0.805159600936\n",
      "SVM(C=10.0, gamma=0.01) score: 0.822039434717\n",
      "SVM(C=10.0, gamma=0.1) score: 0.833349797334\n",
      "SVM(C=10.0, gamma=1) score: 0.839791073024\n",
      "SVM(C=10.0, gamma=10.0) score: 0.831952559079\n",
      "SVM(C=100.0, gamma=0.001) score: 0.822213650745\n",
      "SVM(C=100.0, gamma=0.01) score: 0.833521352232\n",
      "SVM(C=100.0, gamma=0.1) score: 0.83944058728\n",
      "SVM(C=100.0, gamma=1) score: 0.838917814679\n",
      "SVM(C=100.0, gamma=10.0) score: 0.810548679865\n",
      "SVM(C=1000.0, gamma=0.001) score: 0.833173525093\n",
      "SVM(C=1000.0, gamma=0.01) score: 0.837179166956\n",
      "SVM(C=1000.0, gamma=0.1) score: 0.839788289902\n",
      "SVM(C=1000.0, gamma=1) score: 0.829168859174\n",
      "SVM(C=1000.0, gamma=10.0) score: 0.780973834044\n",
      "SVM(C=10000.0, gamma=0.001) score: 0.835612069084\n",
      "SVM(C=10000.0, gamma=0.01) score: 0.839093001603\n",
      "SVM(C=10000.0, gamma=0.1) score: 0.83631050396\n",
      "SVM(C=10000.0, gamma=1) score: 0.818032588069\n",
      "SVM(C=10000.0, gamma=10.0) score: 0.771402848584\n"
     ]
    }
   ],
   "source": [
    "svm_score(theta, doc_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLSA: ARTM thetaless optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4024.0085702\n",
      "1 3991.50885265\n",
      "2 3911.89488681\n",
      "3 3756.1893153\n",
      "4 3493.3368556\n",
      "5 3171.316171\n",
      "6 2915.60988676\n",
      "7 2746.45369508\n",
      "8 2635.80508596\n",
      "9 2560.07395308\n",
      "10 2505.06796354\n",
      "11 2462.82826338\n",
      "12 2429.00455576\n",
      "13 2400.8921662\n",
      "14 2377.21732813\n",
      "15 2358.5833659\n",
      "16 2343.64807915\n",
      "17 2330.81632703\n",
      "18 2319.79565166\n",
      "19 2310.80408502\n",
      "20 2303.31341941\n",
      "21 2297.08052617\n",
      "22 2291.69432531\n",
      "23 2286.87792991\n",
      "24 2282.7277651\n",
      "25 2278.97319887\n",
      "26 2275.56004815\n",
      "27 2272.38892231\n",
      "28 2269.57526931\n",
      "29 2267.0551283\n",
      "30 2264.7551971\n",
      "31 2262.62370833\n",
      "32 2260.66444089\n",
      "33 2258.79769608\n",
      "34 2257.03570419\n",
      "35 2255.33731105\n",
      "36 2253.74794326\n",
      "37 2252.13412785\n",
      "38 2250.58292352\n",
      "39 2249.03407418\n",
      "40 2247.53274389\n",
      "41 2245.99435917\n",
      "42 2244.35455335\n",
      "43 2242.70489286\n",
      "44 2241.0986306\n",
      "45 2239.54583799\n",
      "46 2238.1159281\n",
      "47 2236.85119384\n",
      "48 2235.71748512\n",
      "49 2234.62317682\n",
      "50 2233.62029424\n",
      "51 2232.56358515\n",
      "52 2231.63564977\n",
      "53 2230.71625656\n",
      "54 2230.02567909\n",
      "55 2229.29650379\n",
      "56 2228.6848943\n",
      "57 2227.98746718\n",
      "58 2227.44599568\n",
      "59 2226.81180812\n",
      "60 2226.25755285\n",
      "61 2225.70820938\n",
      "62 2225.25473922\n",
      "63 2224.673093\n",
      "64 2224.21502091\n",
      "65 2223.68294015\n",
      "66 2223.28936305\n",
      "67 2222.79449267\n",
      "68 2222.3594943\n",
      "69 2221.95837625\n",
      "70 2221.50804593\n",
      "71 2221.13763419\n",
      "72 2220.69359262\n",
      "73 2220.29334201\n",
      "74 2219.87202013\n",
      "75 2219.55222551\n",
      "76 2219.18455026\n",
      "77 2218.92899248\n",
      "78 2218.62290016\n",
      "79 2218.38819596\n",
      "80 2218.11044061\n",
      "81 2217.86779956\n",
      "82 2217.58236587\n",
      "83 2217.39405934\n",
      "84 2217.09993816\n",
      "85 2216.87349065\n",
      "86 2216.63843171\n",
      "87 2216.42263873\n",
      "88 2216.20432973\n",
      "89 2216.03839094\n",
      "90 2215.81832922\n",
      "91 2215.64006998\n",
      "92 2215.39624278\n",
      "93 2215.21830865\n",
      "94 2215.00072674\n",
      "95 2214.79689382\n",
      "96 2214.61572382\n",
      "97 2214.41156697\n",
      "98 2214.2514917\n",
      "99 2214.08113872\n",
      "100 2213.95931274\n",
      "101 2213.73787663\n",
      "102 2213.60834514\n",
      "103 2213.40667073\n",
      "104 2213.29215771\n",
      "105 2213.06044594\n",
      "106 2212.88408062\n",
      "107 2212.65264952\n",
      "108 2212.42676552\n",
      "109 2212.11667372\n",
      "110 2211.95404288\n",
      "111 2211.75758849\n",
      "112 2211.66667842\n",
      "113 2211.47548089\n",
      "114 2211.36242345\n",
      "115 2211.20497225\n",
      "116 2211.11521079\n",
      "117 2210.95389981\n",
      "118 2210.88648415\n",
      "119 2210.7465558\n",
      "120 2210.68220671\n",
      "121 2210.55464068\n",
      "122 2210.51964898\n",
      "123 2210.40047477\n",
      "124 2210.35066821\n",
      "125 2210.25963506\n",
      "126 2210.20910239\n",
      "127 2210.05830171\n",
      "128 2209.93426972\n",
      "129 2209.74266207\n",
      "130 2209.63396351\n",
      "131 2209.48591691\n",
      "132 2209.42030257\n",
      "133 2209.31644004\n",
      "134 2209.2543909\n",
      "135 2209.10715835\n",
      "136 2209.01532493\n",
      "137 2208.88594326\n",
      "138 2208.803915\n",
      "139 2208.67561855\n",
      "140 2208.6093347\n",
      "141 2208.50980472\n",
      "142 2208.47355418\n",
      "143 2208.38234874\n",
      "144 2208.34695125\n",
      "145 2208.27369773\n",
      "146 2208.25967729\n",
      "147 2208.17656823\n",
      "148 2208.13456299\n",
      "149 2208.03090422\n",
      "150 2207.96129499\n",
      "151 2207.82887219\n",
      "152 2207.75517747\n",
      "153 2207.63644819\n",
      "154 2207.57234266\n",
      "155 2207.46214628\n",
      "156 2207.41570262\n",
      "157 2207.33183583\n",
      "158 2207.30390645\n",
      "159 2207.2295343\n",
      "160 2207.20966453\n",
      "161 2207.13829889\n",
      "162 2207.11503226\n",
      "163 2207.02228748\n",
      "164 2206.98461869\n",
      "165 2206.91117505\n",
      "166 2206.88381326\n",
      "167 2206.78492197\n",
      "168 2206.75139259\n",
      "169 2206.69579107\n",
      "170 2206.69991948\n",
      "171 2206.65808705\n",
      "172 2206.66520706\n",
      "173 2206.61645161\n",
      "174 2206.62536849\n",
      "175 2206.58839665\n",
      "176 2206.60117448\n",
      "177 2206.55290081\n",
      "178 2206.54487174\n",
      "179 2206.48868757\n",
      "180 2206.48243842\n",
      "181 2206.42394053\n",
      "182 2206.42330948\n",
      "183 2206.36992268\n",
      "184 2206.37289865\n",
      "185 2206.32364627\n",
      "186 2206.33159292\n",
      "187 2206.27817022\n",
      "188 2206.28188292\n",
      "189 2206.22995317\n",
      "190 2206.23825011\n",
      "191 2206.20745752\n",
      "192 2206.22749798\n",
      "193 2206.17749477\n",
      "194 2206.15713777\n",
      "195 2206.07638068\n",
      "196 2206.06559291\n",
      "197 2206.01806522\n",
      "198 2206.02700477\n",
      "199 2205.97415523\n",
      "Iters time 24.0377070904\n",
      "Iters time 14.6083180904\n"
     ]
    }
   ],
   "source": [
    "D, W = origin_n_dw_matrix.shape\n",
    "T = 10\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_matrix = np.random.uniform(size=(T, W)).astype(np.float64)\n",
    "phi_matrix /= np.sum(phi_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "theta_matrix = np.random.uniform(size=(D, T)).astype(np.float64)\n",
    "theta_matrix /= np.sum(theta_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "regularization_list = np.zeros(200, dtype=object)\n",
    "regularization_list[:] = trivial_regularization\n",
    "\n",
    "calc_log_likelihood = create_calculate_likelihood_like_function(\n",
    "    loss_function=LogFunction(),\n",
    "    n_dw_matrix=origin_n_dw_matrix\n",
    ")\n",
    "\n",
    "total_words_number = origin_n_dw_matrix.sum()\n",
    "def callback(it, phi, theta):\n",
    "    print it,  np.exp(- calc_log_likelihood(phi, theta) / total_words_number)\n",
    "\n",
    "phi, theta = artm_thetaless_em_optimization(\n",
    "    n_dw_matrix=origin_n_dw_matrix, \n",
    "    phi_matrix=phi_matrix,\n",
    "    iters_count=200,\n",
    "    iteration_callback=callback\n",
    ")\n",
    "\n",
    "phi, theta = artm_thetaless_em_optimization(\n",
    "    n_dw_matrix=origin_n_dw_matrix, \n",
    "    phi_matrix=phi_matrix,\n",
    "    iters_count=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8232758620689655"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. * np.sum(phi < 1e-20) / np.sum(phi >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(C=1.0, gamma=0.001) score: 0.169276275902\n",
      "SVM(C=1.0, gamma=0.01) score: 0.763220998524\n",
      "SVM(C=1.0, gamma=0.1) score: 0.794023342451\n",
      "SVM(C=1.0, gamma=1) score: 0.809857267576\n",
      "SVM(C=1.0, gamma=10.0) score: 0.813160715497\n",
      "SVM(C=10.0, gamma=0.001) score: 0.762873171385\n",
      "SVM(C=10.0, gamma=0.01) score: 0.795067911708\n",
      "SVM(C=10.0, gamma=0.1) score: 0.810033783802\n",
      "SVM(C=10.0, gamma=1) score: 0.812464819757\n",
      "SVM(C=10.0, gamma=10.0) score: 0.803590210438\n",
      "SVM(C=100.0, gamma=0.001) score: 0.79489369568\n",
      "SVM(C=100.0, gamma=0.01) score: 0.809685956663\n",
      "SVM(C=100.0, gamma=0.1) score: 0.81281639839\n",
      "SVM(C=100.0, gamma=1) score: 0.812288788979\n",
      "SVM(C=100.0, gamma=10.0) score: 0.786367884395\n",
      "SVM(C=1000.0, gamma=0.001) score: 0.809511135718\n",
      "SVM(C=1000.0, gamma=0.01) score: 0.811597493636\n",
      "SVM(C=1000.0, gamma=0.1) score: 0.810376649614\n",
      "SVM(C=1000.0, gamma=1) score: 0.805855870227\n",
      "SVM(C=1000.0, gamma=10.0) score: 0.762350515729\n",
      "SVM(C=10000.0, gamma=0.001) score: 0.811075691931\n",
      "SVM(C=10000.0, gamma=0.01) score: 0.811947257518\n",
      "SVM(C=10000.0, gamma=0.1) score: 0.811419401597\n",
      "SVM(C=10000.0, gamma=1) score: 0.798378133183\n",
      "SVM(C=10000.0, gamma=10.0) score: 0.743389778377\n"
     ]
    }
   ],
   "source": [
    "svm_score(theta, doc_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLSA: gradient optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10077.0201076\n",
      "1 9000.64995398\n",
      "2 8289.15908634\n",
      "3 7760.50577064\n",
      "4 7342.67075424\n",
      "5 6999.46812428\n",
      "6 6709.96890275\n",
      "7 6461.04857097\n",
      "8 6243.80641146\n",
      "9 6052.10960786\n",
      "Iters time 1.23072099686\n",
      "0 4744.99428753\n",
      "1 4306.63558239\n",
      "2 4151.32249368\n",
      "3 4079.85504326\n",
      "4 4062.07593218\n",
      "5 1.17069327399e+14\n",
      "6 11465.8188711\n",
      "7 29660.5365078\n",
      "8 7.83410614953e+15\n",
      "9 16559.559841\n",
      "10 17028976319.6\n",
      "11 5199236221.76\n",
      "12 70325.7605461\n",
      "13 18274.1864573\n",
      "14 5.11136483788e+15\n",
      "15 27374.0089902\n",
      "16 2306294156.96\n",
      "17 15074493884.5\n",
      "18 677606.721354\n",
      "19 16185.5916663\n",
      "20 4.0062959194e+15\n",
      "21 29529.6108698\n",
      "22 1129932083.67\n",
      "23 46022288470.4\n",
      "24 166171.442295\n",
      "25 21157.1392253\n",
      "26 1.27099406952e+16\n",
      "27 17725.0676726\n",
      "28 36847389347.8\n",
      "29 1347481389.94\n",
      "30 248214.08597\n",
      "31 14198.86946\n",
      "32 5.98509703326e+15\n",
      "33 17770.1129828\n",
      "34 2577992927.69\n",
      "35 20001470946.4\n",
      "36 82782.5048572\n",
      "37 15688.0297908\n",
      "38 4.74796193647e+15\n",
      "39 40389.7578963\n",
      "40 1588210356.15\n",
      "41 58005856046.3\n",
      "42 42491.5431418\n",
      "43 56419.2937038\n",
      "44 2.29298387942e+15\n",
      "45 105230.073947\n",
      "46 1535393518.5\n",
      "47 20952123942.4\n",
      "48 31504.8297233\n",
      "49 103245.740606\n",
      "50 1.34289144598e+15\n",
      "51 189462.370988\n",
      "52 1162241866.31\n",
      "53 130955628773.0\n",
      "54 20597.4759725\n",
      "55 173763.246707\n",
      "56 6.95942325496e+14\n",
      "57 338320.12427\n",
      "58 432168190.662\n",
      "59 76953831726.1\n",
      "60 23510.1784531\n",
      "61 104025.229408\n",
      "62 6.09576612756e+14\n",
      "63 307951.660918\n",
      "64 150082211.582\n",
      "65 1.22220606243e+12\n",
      "66 355661.361361\n",
      "67 2035647.19583\n",
      "68 4.89202205795e+12\n",
      "69 6808179.34752\n",
      "70 92829.1239611\n",
      "71 1.37268271849e+14\n",
      "72 505794.343358\n",
      "73 1523095.20886\n",
      "74 2.26816724347e+13\n",
      "75 1041801.11731\n",
      "76 1310739.45628\n",
      "77 2.5478426986e+13\n",
      "78 1447632.19855\n",
      "79 1448209.56208\n",
      "80 4.03505699033e+13\n",
      "81 341677.609555\n",
      "82 6153545.40647\n",
      "83 1.13908379641e+13\n",
      "84 1967209.59512\n",
      "85 2654326.8296\n",
      "86 1.64664420434e+13\n",
      "87 980785.804472\n",
      "88 1523966.57913\n",
      "89 9.85875872261e+12\n",
      "90 1633092.83577\n",
      "91 236487.943719\n",
      "92 7.30492850136e+13\n",
      "93 910827.747196\n",
      "94 2025548.22324\n",
      "95 1.15133916614e+13\n",
      "96 2106319.44539\n",
      "97 447474.22505\n",
      "98 2.85870291245e+13\n",
      "99 2794579.75609\n",
      "100 477262.654426\n",
      "101 4.18796279438e+13\n",
      "102 2576757.32441\n",
      "103 1057490.09193\n",
      "104 1.69025792894e+13\n",
      "105 3868072.84128\n",
      "106 431154.490158\n",
      "107 5.24735340513e+13\n",
      "108 1817471.55211\n",
      "109 1610122.10656\n",
      "110 9.91288800697e+12\n",
      "111 1746777.37437\n",
      "112 228671.586\n",
      "113 2.00593785032e+14\n",
      "114 618847.12573\n",
      "115 19127554.3072\n",
      "116"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-315-b562af74bc7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0miteration_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-313-1cf90cf72288>\u001b[0m in \u001b[0;36mgradient_optimization\u001b[0;34m(n_dw_matrix, phi_matrix, theta_matrix, regularization_gradient_list, iters_count, loss_function, iteration_callback, learning_rate)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miteration_callback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0miteration_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'Iters time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-b562af74bc7e>\u001b[0m in \u001b[0;36mcallback\u001b[0;34m(it, phi, theta)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtotal_words_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morigin_n_dw_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mcalc_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_words_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m phi0, theta0 = gradient_optimization(\n",
      "\u001b[0;32m<ipython-input-17-da400c0c9546>\u001b[0m in \u001b[0;36mfun\u001b[0;34m(phi_matrix, theta_matrix)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0ms_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwordptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_dw_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ms_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "D, W = origin_n_dw_matrix.shape\n",
    "T = 10\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_matrix = np.random.uniform(size=(T, W)).astype(np.float64)\n",
    "phi_matrix /= np.sum(phi_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "theta_matrix = np.random.uniform(size=(D, T)).astype(np.float64)\n",
    "theta_matrix /= np.sum(theta_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "regularization_list = np.zeros(200, dtype=object)\n",
    "regularization_list[:] = trivial_regularization\n",
    "\n",
    "calc_log_likelihood = create_calculate_likelihood_like_function(\n",
    "    loss_function=LogFunction(),\n",
    "    n_dw_matrix=origin_n_dw_matrix\n",
    ")\n",
    "\n",
    "total_words_number = origin_n_dw_matrix.sum()\n",
    "def callback(it, phi, theta):\n",
    "    print it,  np.exp(- calc_log_likelihood(phi, theta) / total_words_number)\n",
    "\n",
    "phi, theta = gradient_optimization(\n",
    "    n_dw_matrix=origin_n_dw_matrix, \n",
    "    phi_matrix=phi_matrix,\n",
    "    theta_matrix=theta_matrix,\n",
    "    regularization_gradient_list=regularization_list,\n",
    "    iters_count=200,\n",
    "    loss_function=LogFunction(),\n",
    "    iteration_callback=callback,\n",
    "    learning_rate=1e-10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7000208565072302"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. * np.sum(phi < 1e-20) / np.sum(phi >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(C=1.0, gamma=0.001) score: 0.169276275902\n",
      "SVM(C=1.0, gamma=0.01) score: 0.169276275902\n",
      "SVM(C=1.0, gamma=0.1) score: 0.169276275902\n",
      "SVM(C=1.0, gamma=1) score: 0.174668379414\n",
      "SVM(C=1.0, gamma=10.0) score: 0.181637749963\n",
      "SVM(C=10.0, gamma=0.001) score: 0.169276275902\n",
      "SVM(C=10.0, gamma=0.01) score: 0.169276275902\n",
      "SVM(C=10.0, gamma=0.1) score: 0.174321035199\n",
      "SVM(C=10.0, gamma=1) score: 0.174499607637\n",
      "SVM(C=10.0, gamma=10.0) score: 0.172241110096\n",
      "SVM(C=100.0, gamma=0.001) score: 0.169276275902\n",
      "SVM(C=100.0, gamma=0.01) score: 0.173624412549\n",
      "SVM(C=100.0, gamma=0.1) score: 0.171713119563\n",
      "SVM(C=100.0, gamma=1) score: 0.182677118955\n",
      "SVM(C=100.0, gamma=10.0) score: 0.170674734086\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-309-d8b2f3e43d5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvm_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-233-9ac2e0c50ffb>\u001b[0m in \u001b[0;36msvm_score\u001b[0;34m(theta, targets)\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm_score(theta, doc_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D, W = big_origin_n_dw_matrix.shape\n",
    "T = 30\n",
    "\n",
    "np.random.seed(5242)\n",
    "\n",
    "phi_matrix = np.random.uniform(size=(T, W)).astype(np.float64)\n",
    "phi_matrix /= np.sum(phi_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "theta_matrix = np.random.uniform(size=(D, T)).astype(np.float64)\n",
    "theta_matrix /= np.sum(theta_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "regularization_list = np.zeros(200, dtype=object)\n",
    "regularization_list[:] = trivial_regularization\n",
    "\n",
    "calc_log_likelihood = create_calculate_likelihood_like_function(\n",
    "    loss_function=LogFunction(),\n",
    "    n_dw_matrix=big_origin_n_dw_matrix\n",
    ")\n",
    "\n",
    "total_words_number = big_origin_n_dw_matrix.sum()\n",
    "def callback(it, phi, theta):\n",
    "    print it,  np.exp(- calc_log_likelihood(phi, theta) / total_words_number)\n",
    "\n",
    "phi, theta = em_optimization(\n",
    "    n_dw_matrix=big_origin_n_dw_matrix, \n",
    "    phi_matrix=phi_matrix,\n",
    "    theta_matrix=theta_matrix,\n",
    "    regularization_list=regularization_list,\n",
    "    iters_count=200,\n",
    "    loss_function=LogFunction(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1. * np.sum(phi < 1e-20) / np.sum(phi >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_score(theta, big_doc_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D, W = big_origin_n_dw_matrix.shape\n",
    "T = 30\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_matrix = np.random.uniform(size=(T, W)).astype(np.float64)\n",
    "phi_matrix /= np.sum(phi_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "theta_matrix = np.random.uniform(size=(D, T)).astype(np.float64)\n",
    "theta_matrix /= np.sum(theta_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "regularization_list = np.zeros(200, dtype=object)\n",
    "regularization_list[:] = trivial_regularization\n",
    "\n",
    "calc_log_likelihood = create_calculate_likelihood_like_function(\n",
    "    loss_function=LogFunction(),\n",
    "    n_dw_matrix=big_origin_n_dw_matrix\n",
    ")\n",
    "\n",
    "total_words_number = big_origin_n_dw_matrix.sum()\n",
    "def callback(it, phi, theta):\n",
    "    print it,  np.exp(- calc_log_likelihood(phi, theta) / total_words_number)\n",
    "\n",
    "phi, theta = naive_thetaless_em_optimization(\n",
    "    n_dw_matrix=big_origin_n_dw_matrix, \n",
    "    phi_matrix=phi_matrix,\n",
    "    regularization_list=regularization_list,\n",
    "    iters_count=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1. * np.sum(phi < 1e-20) / np.sum(phi >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_score(theta, big_doc_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iters time 191.425027847\n"
     ]
    }
   ],
   "source": [
    "D, W = big_origin_n_dw_matrix.shape\n",
    "T = 30\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_matrix = np.random.uniform(size=(T, W)).astype(np.float64)\n",
    "phi_matrix /= np.sum(phi_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "theta_matrix = np.random.uniform(size=(D, T)).astype(np.float64)\n",
    "theta_matrix /= np.sum(theta_matrix, axis=1)[:, np.newaxis]\n",
    "\n",
    "regularization_list = np.zeros(200, dtype=object)\n",
    "regularization_list[:] = trivial_regularization\n",
    "\n",
    "calc_log_likelihood = create_calculate_likelihood_like_function(\n",
    "    loss_function=LogFunction(),\n",
    "    n_dw_matrix=big_origin_n_dw_matrix\n",
    ")\n",
    "\n",
    "total_words_number = big_origin_n_dw_matrix.sum()\n",
    "def callback(it, phi, theta):\n",
    "    print it,  np.exp(- calc_log_likelihood(phi, theta) / total_words_number)\n",
    "\n",
    "phi, theta = artm_thetaless_em_optimization(\n",
    "    n_dw_matrix=big_origin_n_dw_matrix, \n",
    "    phi_matrix=phi_matrix,\n",
    "    iters_count=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317146165104747"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. * np.sum(phi < 1e-20) / np.sum(phi >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(C=1.0, gamma=0.001) score: 0.0534981417557\n",
      "SVM(C=1.0, gamma=0.01) score: 0.353752725393\n",
      "SVM(C=1.0, gamma=0.1) score: 0.528856637738\n",
      "SVM(C=1.0, gamma=1) score: 0.552428969197\n",
      "SVM(C=1.0, gamma=10.0) score: 0.568894035616\n"
     ]
    }
   ],
   "source": [
    "svm_score(theta, big_doc_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
